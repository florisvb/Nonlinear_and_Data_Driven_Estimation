{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d49ebfd-892f-4df7-8725-4da0d1cc0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1006a5f-7c06-467b-b245-94be16d08224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caveman/PY38/lib/python3.8/site-packages/do_mpc/sysid/__init__.py:15: UserWarning: The ONNX feature is not available. Please install the full version of do-mpc to access this feature.\n",
      "  warnings.warn('The ONNX feature is not available. Please install the full version of do-mpc to access this feature.')\n",
      "/home/caveman/PY38/lib/python3.8/site-packages/do_mpc/opcua/__init__.py:14: UserWarning: The opcua feature is not available. Please install the full version of do-mpc to access this feature.\n",
      "  warnings.warn('The opcua feature is not available. Please install the full version of do-mpc to access this feature.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests\n",
    "import importlib\n",
    "\n",
    "def import_local_or_github(package_name, function_name=None, directory=None, giturl=None):\n",
    "    # Import functions directly from github\n",
    "    # Important: note that we use raw.githubusercontent.com, not github.com\n",
    "\n",
    "    try: # to find the file locally\n",
    "        if directory is not None:\n",
    "            if directory not in sys.path:\n",
    "                sys.path.append(directory)\n",
    "    \n",
    "        package = importlib.import_module(package_name)\n",
    "        if function_name is not None:\n",
    "            function = getattr(package, function_name)\n",
    "            return function\n",
    "        else:\n",
    "            return package\n",
    "\n",
    "    except: # get the file from github\n",
    "        if giturl is None:\n",
    "            giturl = 'https://raw.githubusercontent.com/florisvb/Nonlinear_and_Data_Driven_Estimation/main/Utility/' + str(package_name) + '.py'\n",
    "        \n",
    "        r = requests.get(giturl)\n",
    "        print('Fetching from: ')\n",
    "        print(r)\n",
    "    \n",
    "        # Store the file to the colab working directory\n",
    "        with open(package_name+'.py', 'w') as f:\n",
    "            f.write(r.text)\n",
    "        f.close()\n",
    "    \n",
    "        # import the function we want from that file\n",
    "        package = importlib.import_module(package_name)\n",
    "        if function_name is not None:\n",
    "            function = getattr(package, function_name)\n",
    "            return function\n",
    "        else:\n",
    "            return package\n",
    "\n",
    "planar_drone = import_local_or_github('planar_drone', directory='../Utility')\n",
    "plot_tme = import_local_or_github('plot_utility', 'plot_tme', directory='../Utility')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638379c-1a56-472c-9302-bb4a4c6adc5f",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "And format it so the shapes and organization of the data matches standard mathematical notation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39f7e5-b7e2-4ce6-8302-c0f8815d0e98",
   "metadata": {},
   "source": [
    "### Load the arrays for the kalman filter\n",
    "\n",
    "Colab tip: You may need to download them to your machine from notebook A, and then upload them to the colab environment where you are running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c18d6ad4-464c-472d-a580-1f015fdda13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from disk\n",
    "loaded_arrays = np.load('ABCDRQ.npz')\n",
    "A = loaded_arrays['A']\n",
    "B = loaded_arrays['B']\n",
    "C = loaded_arrays['C']\n",
    "D = loaded_arrays['D']\n",
    "R = loaded_arrays['R']\n",
    "Q = loaded_arrays['Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "537b3792-cdc9-4157-9c13-a278d5e03f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape:  (7, 7)\n",
      "B shape:  (7, 2)\n",
      "C shape:  (4, 7)\n",
      "D shape:  (4, 2)\n",
      "R shape:  (4, 4)\n",
      "Q shape:  (7, 7)\n"
     ]
    }
   ],
   "source": [
    "print('A shape: ', A.shape)\n",
    "print('B shape: ', B.shape)\n",
    "print('C shape: ', C.shape)\n",
    "print('D shape: ', D.shape)\n",
    "print('R shape: ', R.shape)\n",
    "print('Q shape: ', Q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da9db7-4e8d-43fb-9bec-945b33019aa5",
   "metadata": {},
   "source": [
    "### Load the state data and reorganize Y and U\n",
    "\n",
    "Standard mathematical notation requires that each column of $Y$ correspond to the measurements at discrete time, i.e. $\\mathbf{y}_k$, and each row of $\\mathbf{y}$ correspond to each individual measurement. Similarly for $U$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b48921-c19d-4ea1-98de-95cdffa94136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from disk\n",
    "df_states = pandas.read_hdf('planar_drone_states.hdf')\n",
    "df_measurements_true = pandas.read_hdf('planar_drone_measurements_true.hdf')\n",
    "df_measurements_noisy = pandas.read_hdf('planar_drone_measurements_noisy.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1b99ed-0d35-4d87-9633-85c2f9757045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 200)\n"
     ]
    }
   ],
   "source": [
    "Y = np.vstack(df_measurements_noisy[['theta', 'x', 'z', 'k']].values).T\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb3f908-c615-4f7f-a4ff-e9d518480ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 200)\n"
     ]
    }
   ],
   "source": [
    "U = np.vstack(df_states[['j1', 'j2']].values).T\n",
    "print(U.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83da467-ba5c-44b5-b4dc-7deefabc9740",
   "metadata": {},
   "source": [
    "### Tip: When you index Y or U, make sure you are keeping a column vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ffee2a-8b0b-447a-a979-f9bf5cf8ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22321732 0.81268371 0.63948923 0.99070634]\n"
     ]
    }
   ],
   "source": [
    "# This is wrong\n",
    "y_0 = Y[:, 0]\n",
    "print(y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e45487b-8338-4ab9-96bd-2b0470af645c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22321732]\n",
      " [0.81268371]\n",
      " [0.63948923]\n",
      " [0.99070634]]\n"
     ]
    }
   ],
   "source": [
    "# This is right\n",
    "y_0 = Y[:, [0]]\n",
    "print(y_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd505ef-774b-48cf-b522-abe5c6892455",
   "metadata": {},
   "source": [
    "## Tip: matrix multiplication in python\n",
    "\n",
    "Recall that matrix shape during multiplication works like: \n",
    "\n",
    "$[N\\times M][M\\times 1]=[N\\times 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1214a399-0836-4af9-9f4d-7183ff2aee03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R shape:  (4, 4)\n",
      "y_0 shape:  (4, 1)\n",
      "[R x y_0] shape (4, 1)\n",
      "\n",
      "[R x y_0] = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.23217318e-03],\n",
       "       [3.25073486e-02],\n",
       "       [1.02318277e-01],\n",
       "       [9.90706342e-05]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1 using arrays\n",
    "print('R shape: ', R.shape)\n",
    "print('y_0 shape: ', y_0.shape)\n",
    "print('[R x y_0] shape', (R@y_0).shape)\n",
    "print('')\n",
    "print('[R x y_0] = ')\n",
    "R@y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba5298d6-9dd8-40f4-be68-4c80c6cfe85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[R x y_0] = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[2.23217318e-03],\n",
       "        [3.25073486e-02],\n",
       "        [1.02318277e-01],\n",
       "        [9.90706342e-05]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2 using matrices -- NOTE: np.matrix is getting deprecated, sadly, so this is not recommended\n",
    "R_times_y_0 = np.matrix(R)*np.matrix(y_0)\n",
    "print('[R x y_0] = ')\n",
    "R_times_y_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46647cfe-063e-4ee6-8835-5408cdb47e64",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "\n",
    "1. Code a linear discrete Kalman filter that uses the matrices and time series data defined above:\n",
    "    * $A, B, C, D, R, Q$ matrices defined above\n",
    "    * Measurements are given by $Y$\n",
    "    * Controls are given by $U$\n",
    "    * Choose an initial $\\mathbf{x_0}$ and $P_0$\n",
    "    * Try a larger value of Q, and a smaller value of Q. For this problem, does a larger or smaller value of Q lead to more accurate estimates? Why do you think that is?\n",
    "\n",
    "2. Compare the error covariance of your Kalman filter to the Cramer Rao Bound. Is your KF efficient? Try for different values of Q.\n",
    "\n",
    "3. Compare the error covariance of your KF and the CRB to the actual errors in your estimate. Does the distribution of the errors match that predicted by the error covariance and the CRB? Hint: the error covariance and the CRB report variance, the square of the standard deviation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
