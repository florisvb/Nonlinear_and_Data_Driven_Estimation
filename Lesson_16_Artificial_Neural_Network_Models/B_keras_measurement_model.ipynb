{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7924c0-5bf4-4df8-ac73-f71c05249a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 12:42:32.949497: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-16 12:42:33.010517: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-16 12:42:33.011871: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-16 12:42:33.990775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras_visualizer import visualizer\n",
    "from IPython.display import display, Image\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adddcd2c-d819-49dd-916a-6d6f5ecfc697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caveman/PY38/lib/python3.8/site-packages/do_mpc/sysid/__init__.py:15: UserWarning: The ONNX feature is not available. Please install the full version of do-mpc to access this feature.\n",
      "  warnings.warn('The ONNX feature is not available. Please install the full version of do-mpc to access this feature.')\n",
      "/home/caveman/PY38/lib/python3.8/site-packages/do_mpc/opcua/__init__.py:14: UserWarning: The opcua feature is not available. Please install the full version of do-mpc to access this feature.\n",
      "  warnings.warn('The opcua feature is not available. Please install the full version of do-mpc to access this feature.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests\n",
    "import importlib\n",
    "\n",
    "def import_local_or_github(package_name, function_name=None, directory=None, giturl=None):\n",
    "    # Import functions directly from github\n",
    "    # Important: note that we use raw.githubusercontent.com, not github.com\n",
    "\n",
    "    try: # to find the file locally\n",
    "        if directory is not None:\n",
    "            if directory not in sys.path:\n",
    "                sys.path.append(directory)\n",
    "\n",
    "        package = importlib.import_module(package_name)\n",
    "        if function_name is not None:\n",
    "            function = getattr(package, function_name)\n",
    "            return function\n",
    "        else:\n",
    "            return package\n",
    "\n",
    "    except: # get the file from github\n",
    "        if giturl is None:\n",
    "            giturl = 'https://raw.githubusercontent.com/florisvb/Nonlinear_and_Data_Driven_Estimation/main/Utility/' + str(package_name) + '.py'\n",
    "\n",
    "        r = requests.get(giturl)\n",
    "        print('Fetching from: ')\n",
    "        print(r)\n",
    "\n",
    "        # Store the file to the colab working directory\n",
    "        with open(package_name+'.py', 'w') as f:\n",
    "            f.write(r.text)\n",
    "        f.close()\n",
    "\n",
    "        # import the function we want from that file\n",
    "        package = importlib.import_module(package_name)\n",
    "        if function_name is not None:\n",
    "            function = getattr(package , function_name)\n",
    "            return function\n",
    "        else:\n",
    "            return package\n",
    "\n",
    "planar_drone = import_local_or_github('planar_drone', directory='../Utility')\n",
    "plot_tme = import_local_or_github('plot_utility', 'plot_tme', directory='../Utility')\n",
    "generate_training_data_utility = import_local_or_github('generate_training_data_utility', directory='../Utility')\n",
    "keras_ann_utility = import_local_or_github('keras_ann_utility', directory='../Utility')\n",
    "keras_advanced_utility = import_local_or_github('keras_advanced_utility', directory='../Utility')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff3dcf-365d-43f1-9f46-49aecbe2c423",
   "metadata": {},
   "source": [
    "# Download, load, clean, and add noise to data as in Lesson 12.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699c6358-5546-4d40-88fc-6f5e31c27bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from: https://raw.githubusercontent.com/florisvb/Nonlinear_and_Data_Driven_Estimation/main/Data/planar_drone_trajectories.zip\n",
      "Successfully downloaded planar_drone_trajectories.zip (29316396 bytes)\n",
      "unzipping...\n",
      "Number of trajectories: \n",
      "3001\n",
      "Number of good trajectories: \n",
      "2924\n"
     ]
    }
   ],
   "source": [
    "generate_training_data_utility.download_data('planar_drone_trajectories.zip')\n",
    "traj_list = generate_training_data_utility.load_trajectory_data('planar_drone_trajectories')\n",
    "traj_list = generate_training_data_utility.clean_trajectory_data(traj_list)\n",
    "traj_list = generate_training_data_utility.add_noise_to_trajectory_data(traj_list, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbaa1e5-eca7-453a-98ab-6c65b909d55c",
   "metadata": {},
   "source": [
    "# Build augmented data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dea0b2-2632-48a5-a3e0-97c6f0f60183",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names =  ['theta', 'theta_dot', 'x', 'x_dot', 'z', 'z_dot'] \n",
    "control_names = ['j1', 'j2']\n",
    "output_names = ['sensor_optic_flow', 'sensor_theta', 'sensor_theta_dot', 'sensor_accel_x', 'sensor_accel_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0587c623-c53e-4b4f-a73d-a86ee0c1de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_offsets = [0, -1]\n",
    "control_offsets = [0, -1]\n",
    "output_offsets = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aeb838f-5230-4cf9-8139-be14b81c755a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta_offset_0</th>\n",
       "      <th>theta_dot_offset_0</th>\n",
       "      <th>x_offset_0</th>\n",
       "      <th>x_dot_offset_0</th>\n",
       "      <th>z_offset_0</th>\n",
       "      <th>z_dot_offset_0</th>\n",
       "      <th>theta_offset_-1</th>\n",
       "      <th>theta_dot_offset_-1</th>\n",
       "      <th>x_offset_-1</th>\n",
       "      <th>x_dot_offset_-1</th>\n",
       "      <th>z_offset_-1</th>\n",
       "      <th>z_dot_offset_-1</th>\n",
       "      <th>j1_offset_0</th>\n",
       "      <th>j2_offset_0</th>\n",
       "      <th>j1_offset_-1</th>\n",
       "      <th>j2_offset_-1</th>\n",
       "      <th>sensor_optic_flow_offset_0</th>\n",
       "      <th>sensor_theta_offset_0</th>\n",
       "      <th>sensor_theta_dot_offset_0</th>\n",
       "      <th>sensor_accel_x_offset_0</th>\n",
       "      <th>sensor_accel_z_offset_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.1418</td>\n",
       "      <td>-16.5923</td>\n",
       "      <td>-17.5827</td>\n",
       "      <td>3.1027</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>2.8330</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>11.3867</td>\n",
       "      <td>-17.9304</td>\n",
       "      <td>4.4794</td>\n",
       "      <td>1.0458</td>\n",
       "      <td>-1.8849</td>\n",
       "      <td>8.0492</td>\n",
       "      <td>75.7452</td>\n",
       "      <td>-11.1830</td>\n",
       "      <td>59.7404</td>\n",
       "      <td>2.8555</td>\n",
       "      <td>-0.1297</td>\n",
       "      <td>-16.5692</td>\n",
       "      <td>10.0820</td>\n",
       "      <td>65.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.7740</td>\n",
       "      <td>3.5839</td>\n",
       "      <td>-17.0410</td>\n",
       "      <td>7.4923</td>\n",
       "      <td>1.6235</td>\n",
       "      <td>7.8768</td>\n",
       "      <td>-0.1418</td>\n",
       "      <td>-16.5923</td>\n",
       "      <td>-17.5827</td>\n",
       "      <td>3.1027</td>\n",
       "      <td>1.0867</td>\n",
       "      <td>2.8330</td>\n",
       "      <td>-2.3801</td>\n",
       "      <td>72.3657</td>\n",
       "      <td>8.0492</td>\n",
       "      <td>75.7452</td>\n",
       "      <td>4.5616</td>\n",
       "      <td>-0.7970</td>\n",
       "      <td>3.5455</td>\n",
       "      <td>51.1484</td>\n",
       "      <td>41.3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.7184</td>\n",
       "      <td>-2.3685</td>\n",
       "      <td>-16.0715</td>\n",
       "      <td>12.2042</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>12.3902</td>\n",
       "      <td>-0.7740</td>\n",
       "      <td>3.5839</td>\n",
       "      <td>-17.0410</td>\n",
       "      <td>7.4923</td>\n",
       "      <td>1.6235</td>\n",
       "      <td>7.8768</td>\n",
       "      <td>1.4152</td>\n",
       "      <td>54.4326</td>\n",
       "      <td>-2.3801</td>\n",
       "      <td>72.3657</td>\n",
       "      <td>4.5406</td>\n",
       "      <td>-0.7157</td>\n",
       "      <td>-2.3828</td>\n",
       "      <td>36.1400</td>\n",
       "      <td>30.8971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.7619</td>\n",
       "      <td>1.1836</td>\n",
       "      <td>-14.6472</td>\n",
       "      <td>16.0368</td>\n",
       "      <td>4.0293</td>\n",
       "      <td>15.2480</td>\n",
       "      <td>-0.7184</td>\n",
       "      <td>-2.3685</td>\n",
       "      <td>-16.0715</td>\n",
       "      <td>12.2042</td>\n",
       "      <td>2.6601</td>\n",
       "      <td>12.3902</td>\n",
       "      <td>-0.8033</td>\n",
       "      <td>31.5578</td>\n",
       "      <td>1.4152</td>\n",
       "      <td>54.4326</td>\n",
       "      <td>3.9853</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>1.1889</td>\n",
       "      <td>22.2908</td>\n",
       "      <td>12.4992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.7637</td>\n",
       "      <td>-0.7643</td>\n",
       "      <td>-12.9502</td>\n",
       "      <td>18.2044</td>\n",
       "      <td>5.6204</td>\n",
       "      <td>16.5783</td>\n",
       "      <td>-0.7619</td>\n",
       "      <td>1.1836</td>\n",
       "      <td>-14.6472</td>\n",
       "      <td>16.0368</td>\n",
       "      <td>4.0293</td>\n",
       "      <td>15.2480</td>\n",
       "      <td>0.4904</td>\n",
       "      <td>10.8784</td>\n",
       "      <td>-0.8033</td>\n",
       "      <td>31.5578</td>\n",
       "      <td>3.2409</td>\n",
       "      <td>-0.7633</td>\n",
       "      <td>-0.8192</td>\n",
       "      <td>7.5193</td>\n",
       "      <td>-1.9770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260231</th>\n",
       "      <td>0.1179</td>\n",
       "      <td>1.4377</td>\n",
       "      <td>1.4046</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>18.6757</td>\n",
       "      <td>1.4888</td>\n",
       "      <td>0.2029</td>\n",
       "      <td>-3.1839</td>\n",
       "      <td>1.3560</td>\n",
       "      <td>0.4383</td>\n",
       "      <td>18.4977</td>\n",
       "      <td>1.8236</td>\n",
       "      <td>1.0029</td>\n",
       "      <td>3.2105</td>\n",
       "      <td>1.8880</td>\n",
       "      <td>6.3435</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>1.4332</td>\n",
       "      <td>-0.3440</td>\n",
       "      <td>-6.6206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260232</th>\n",
       "      <td>0.4004</td>\n",
       "      <td>3.9516</td>\n",
       "      <td>1.4050</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>18.7618</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.1179</td>\n",
       "      <td>1.4377</td>\n",
       "      <td>1.4046</td>\n",
       "      <td>0.3253</td>\n",
       "      <td>18.6757</td>\n",
       "      <td>1.4888</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>2.0298</td>\n",
       "      <td>1.0029</td>\n",
       "      <td>3.2105</td>\n",
       "      <td>-0.0138</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>3.9407</td>\n",
       "      <td>-0.7364</td>\n",
       "      <td>-7.9284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260233</th>\n",
       "      <td>0.6460</td>\n",
       "      <td>2.0458</td>\n",
       "      <td>1.4515</td>\n",
       "      <td>0.1698</td>\n",
       "      <td>18.8009</td>\n",
       "      <td>-0.0297</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>3.9516</td>\n",
       "      <td>1.4050</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>18.7618</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>-0.8198</td>\n",
       "      <td>2.3389</td>\n",
       "      <td>-0.7430</td>\n",
       "      <td>2.0298</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.7064</td>\n",
       "      <td>2.0834</td>\n",
       "      <td>-1.4761</td>\n",
       "      <td>-7.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260234</th>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>1.4396</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>18.8282</td>\n",
       "      <td>-0.8096</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>2.0458</td>\n",
       "      <td>1.4515</td>\n",
       "      <td>0.1698</td>\n",
       "      <td>18.8009</td>\n",
       "      <td>-0.0297</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>2.9830</td>\n",
       "      <td>-0.8198</td>\n",
       "      <td>2.3389</td>\n",
       "      <td>-0.0253</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>-0.0115</td>\n",
       "      <td>-2.1263</td>\n",
       "      <td>-7.6949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260235</th>\n",
       "      <td>0.7666</td>\n",
       "      <td>-0.0287</td>\n",
       "      <td>1.4623</td>\n",
       "      <td>-0.2192</td>\n",
       "      <td>18.6282</td>\n",
       "      <td>-1.5648</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>1.4396</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>18.8282</td>\n",
       "      <td>-0.8096</td>\n",
       "      <td>-0.0146</td>\n",
       "      <td>3.8756</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>2.9830</td>\n",
       "      <td>-0.0199</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>-2.7818</td>\n",
       "      <td>-7.0477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260236 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        theta_offset_0  theta_dot_offset_0  x_offset_0  x_dot_offset_0   \n",
       "0              -0.1418            -16.5923    -17.5827          3.1027  \\\n",
       "1              -0.7740              3.5839    -17.0410          7.4923   \n",
       "2              -0.7184             -2.3685    -16.0715         12.2042   \n",
       "3              -0.7619              1.1836    -14.6472         16.0368   \n",
       "4              -0.7637             -0.7643    -12.9502         18.2044   \n",
       "...                ...                 ...         ...             ...   \n",
       "260231          0.1179              1.4377      1.4046          0.3253   \n",
       "260232          0.4004              3.9516      1.4050          0.2504   \n",
       "260233          0.6460              2.0458      1.4515          0.1698   \n",
       "260234          0.7855              0.0193      1.4396         -0.0029   \n",
       "260235          0.7666             -0.0287      1.4623         -0.2192   \n",
       "\n",
       "        z_offset_0  z_dot_offset_0  theta_offset_-1  theta_dot_offset_-1   \n",
       "0           1.0867          2.8330           0.1430              11.3867  \\\n",
       "1           1.6235          7.8768          -0.1418             -16.5923   \n",
       "2           2.6601         12.3902          -0.7740               3.5839   \n",
       "3           4.0293         15.2480          -0.7184              -2.3685   \n",
       "4           5.6204         16.5783          -0.7619               1.1836   \n",
       "...            ...             ...              ...                  ...   \n",
       "260231     18.6757          1.4888           0.2029              -3.1839   \n",
       "260232     18.7618          0.8048           0.1179               1.4377   \n",
       "260233     18.8009         -0.0297           0.4004               3.9516   \n",
       "260234     18.8282         -0.8096           0.6460               2.0458   \n",
       "260235     18.6282         -1.5648           0.7855               0.0193   \n",
       "\n",
       "        x_offset_-1  x_dot_offset_-1  z_offset_-1  z_dot_offset_-1   \n",
       "0          -17.9304           4.4794       1.0458          -1.8849  \\\n",
       "1          -17.5827           3.1027       1.0867           2.8330   \n",
       "2          -17.0410           7.4923       1.6235           7.8768   \n",
       "3          -16.0715          12.2042       2.6601          12.3902   \n",
       "4          -14.6472          16.0368       4.0293          15.2480   \n",
       "...             ...              ...          ...              ...   \n",
       "260231       1.3560           0.4383      18.4977           1.8236   \n",
       "260232       1.4046           0.3253      18.6757           1.4888   \n",
       "260233       1.4050           0.2504      18.7618           0.8048   \n",
       "260234       1.4515           0.1698      18.8009          -0.0297   \n",
       "260235       1.4396          -0.0029      18.8282          -0.8096   \n",
       "\n",
       "        j1_offset_0  j2_offset_0  j1_offset_-1  j2_offset_-1   \n",
       "0            8.0492      75.7452      -11.1830       59.7404  \\\n",
       "1           -2.3801      72.3657        8.0492       75.7452   \n",
       "2            1.4152      54.4326       -2.3801       72.3657   \n",
       "3           -0.8033      31.5578        1.4152       54.4326   \n",
       "4            0.4904      10.8784       -0.8033       31.5578   \n",
       "...             ...          ...           ...           ...   \n",
       "260231       1.0029       3.2105        1.8880        6.3435   \n",
       "260232      -0.7430       2.0298        1.0029        3.2105   \n",
       "260233      -0.8198       2.3389       -0.7430        2.0298   \n",
       "260234       0.0282       2.9830       -0.8198        2.3389   \n",
       "260235      -0.0146       3.8756        0.0282        2.9830   \n",
       "\n",
       "        sensor_optic_flow_offset_0  sensor_theta_offset_0   \n",
       "0                           2.8555                -0.1297  \\\n",
       "1                           4.5616                -0.7970   \n",
       "2                           4.5406                -0.7157   \n",
       "3                           3.9853                -0.8000   \n",
       "4                           3.2409                -0.7633   \n",
       "...                            ...                    ...   \n",
       "260231                      0.0008                 0.0844   \n",
       "260232                     -0.0138                 0.3699   \n",
       "260233                      0.0378                 0.7064   \n",
       "260234                     -0.0253                 0.7517   \n",
       "260235                     -0.0199                 0.7579   \n",
       "\n",
       "        sensor_theta_dot_offset_0  sensor_accel_x_offset_0   \n",
       "0                        -16.5692                  10.0820  \\\n",
       "1                          3.5455                  51.1484   \n",
       "2                         -2.3828                  36.1400   \n",
       "3                          1.1889                  22.2908   \n",
       "4                         -0.8192                   7.5193   \n",
       "...                           ...                      ...   \n",
       "260231                     1.4332                  -0.3440   \n",
       "260232                     3.9407                  -0.7364   \n",
       "260233                     2.0834                  -1.4761   \n",
       "260234                    -0.0115                  -2.1263   \n",
       "260235                     0.0145                  -2.7818   \n",
       "\n",
       "        sensor_accel_z_offset_0  \n",
       "0                       65.2603  \n",
       "1                       41.3044  \n",
       "2                       30.8971  \n",
       "3                       12.4992  \n",
       "4                       -1.9770  \n",
       "...                         ...  \n",
       "260231                  -6.6206  \n",
       "260232                  -7.9284  \n",
       "260233                  -7.9760  \n",
       "260234                  -7.6949  \n",
       "260235                  -7.0477  \n",
       "\n",
       "[260236 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_augment_list = []\n",
    "for traj in traj_list:\n",
    "    traj_augment = keras_ann_utility.collect_offset_rows(traj, states=state_names, controls=control_names, outputs=output_names, \n",
    "                        state_offsets=state_offsets, control_offsets=control_offsets, output_offsets=output_offsets)\n",
    "    \n",
    "    traj_augment_list.append(traj_augment)\n",
    "\n",
    "traj_augment_all = pd.concat(traj_augment_list, ignore_index=True)\n",
    "\n",
    "np.round(traj_augment_all, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2da2dd-5ee6-4b68-a669-03584eccb3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States: 6\n",
      "Controls: 2\n",
      "Outputs: 5\n",
      "Delay embedding: 2\n"
     ]
    }
   ],
   "source": [
    "n_state = len(state_names)\n",
    "n_control = len(control_names)\n",
    "n_output = len(output_names)\n",
    "delay_embedding = len(state_offsets)\n",
    "\n",
    "print('States:', n_state)\n",
    "print('Controls:', n_control)\n",
    "print('Outputs:', n_output)\n",
    "print('Delay embedding:', delay_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be3d316e-10be-4421-b1ee-14c823824a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta_offset_0</th>\n",
       "      <th>theta_dot_offset_0</th>\n",
       "      <th>x_offset_0</th>\n",
       "      <th>x_dot_offset_0</th>\n",
       "      <th>z_offset_0</th>\n",
       "      <th>z_dot_offset_0</th>\n",
       "      <th>theta_offset_-1</th>\n",
       "      <th>theta_dot_offset_-1</th>\n",
       "      <th>x_offset_-1</th>\n",
       "      <th>x_dot_offset_-1</th>\n",
       "      <th>z_offset_-1</th>\n",
       "      <th>z_dot_offset_-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.141752</td>\n",
       "      <td>-16.592314</td>\n",
       "      <td>-17.582732</td>\n",
       "      <td>3.102667</td>\n",
       "      <td>1.086747</td>\n",
       "      <td>2.833017</td>\n",
       "      <td>0.142958</td>\n",
       "      <td>11.386702</td>\n",
       "      <td>-17.930353</td>\n",
       "      <td>4.479441</td>\n",
       "      <td>1.045827</td>\n",
       "      <td>-1.884903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.774046</td>\n",
       "      <td>3.583935</td>\n",
       "      <td>-17.041003</td>\n",
       "      <td>7.492268</td>\n",
       "      <td>1.623483</td>\n",
       "      <td>7.876772</td>\n",
       "      <td>-0.141752</td>\n",
       "      <td>-16.592314</td>\n",
       "      <td>-17.582732</td>\n",
       "      <td>3.102667</td>\n",
       "      <td>1.086747</td>\n",
       "      <td>2.833017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.718386</td>\n",
       "      <td>-2.368497</td>\n",
       "      <td>-16.071539</td>\n",
       "      <td>12.204198</td>\n",
       "      <td>2.660148</td>\n",
       "      <td>12.390169</td>\n",
       "      <td>-0.774046</td>\n",
       "      <td>3.583935</td>\n",
       "      <td>-17.041003</td>\n",
       "      <td>7.492268</td>\n",
       "      <td>1.623483</td>\n",
       "      <td>7.876772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.761949</td>\n",
       "      <td>1.183639</td>\n",
       "      <td>-14.647161</td>\n",
       "      <td>16.036803</td>\n",
       "      <td>4.029298</td>\n",
       "      <td>15.247972</td>\n",
       "      <td>-0.718386</td>\n",
       "      <td>-2.368497</td>\n",
       "      <td>-16.071539</td>\n",
       "      <td>12.204198</td>\n",
       "      <td>2.660148</td>\n",
       "      <td>12.390169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.763652</td>\n",
       "      <td>-0.764257</td>\n",
       "      <td>-12.950233</td>\n",
       "      <td>18.204426</td>\n",
       "      <td>5.620429</td>\n",
       "      <td>16.578333</td>\n",
       "      <td>-0.761949</td>\n",
       "      <td>1.183639</td>\n",
       "      <td>-14.647161</td>\n",
       "      <td>16.036803</td>\n",
       "      <td>4.029298</td>\n",
       "      <td>15.247972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260231</th>\n",
       "      <td>0.117936</td>\n",
       "      <td>1.437662</td>\n",
       "      <td>1.404614</td>\n",
       "      <td>0.325322</td>\n",
       "      <td>18.675687</td>\n",
       "      <td>1.488769</td>\n",
       "      <td>0.202850</td>\n",
       "      <td>-3.183932</td>\n",
       "      <td>1.355991</td>\n",
       "      <td>0.438261</td>\n",
       "      <td>18.497738</td>\n",
       "      <td>1.823627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260232</th>\n",
       "      <td>0.400448</td>\n",
       "      <td>3.951609</td>\n",
       "      <td>1.405008</td>\n",
       "      <td>0.250367</td>\n",
       "      <td>18.761771</td>\n",
       "      <td>0.804798</td>\n",
       "      <td>0.117936</td>\n",
       "      <td>1.437662</td>\n",
       "      <td>1.404614</td>\n",
       "      <td>0.325322</td>\n",
       "      <td>18.675687</td>\n",
       "      <td>1.488769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260233</th>\n",
       "      <td>0.645956</td>\n",
       "      <td>2.045812</td>\n",
       "      <td>1.451527</td>\n",
       "      <td>0.169752</td>\n",
       "      <td>18.800924</td>\n",
       "      <td>-0.029675</td>\n",
       "      <td>0.400448</td>\n",
       "      <td>3.951609</td>\n",
       "      <td>1.405008</td>\n",
       "      <td>0.250367</td>\n",
       "      <td>18.761771</td>\n",
       "      <td>0.804798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260234</th>\n",
       "      <td>0.785484</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>1.439573</td>\n",
       "      <td>-0.002924</td>\n",
       "      <td>18.828193</td>\n",
       "      <td>-0.809622</td>\n",
       "      <td>0.645956</td>\n",
       "      <td>2.045812</td>\n",
       "      <td>1.451527</td>\n",
       "      <td>0.169752</td>\n",
       "      <td>18.800924</td>\n",
       "      <td>-0.029675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260235</th>\n",
       "      <td>0.766603</td>\n",
       "      <td>-0.028737</td>\n",
       "      <td>1.462290</td>\n",
       "      <td>-0.219199</td>\n",
       "      <td>18.628204</td>\n",
       "      <td>-1.564804</td>\n",
       "      <td>0.785484</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>1.439573</td>\n",
       "      <td>-0.002924</td>\n",
       "      <td>18.828193</td>\n",
       "      <td>-0.809622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260236 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        theta_offset_0  theta_dot_offset_0  x_offset_0  x_dot_offset_0   \n",
       "0            -0.141752          -16.592314  -17.582732        3.102667  \\\n",
       "1            -0.774046            3.583935  -17.041003        7.492268   \n",
       "2            -0.718386           -2.368497  -16.071539       12.204198   \n",
       "3            -0.761949            1.183639  -14.647161       16.036803   \n",
       "4            -0.763652           -0.764257  -12.950233       18.204426   \n",
       "...                ...                 ...         ...             ...   \n",
       "260231        0.117936            1.437662    1.404614        0.325322   \n",
       "260232        0.400448            3.951609    1.405008        0.250367   \n",
       "260233        0.645956            2.045812    1.451527        0.169752   \n",
       "260234        0.785484            0.019339    1.439573       -0.002924   \n",
       "260235        0.766603           -0.028737    1.462290       -0.219199   \n",
       "\n",
       "        z_offset_0  z_dot_offset_0  theta_offset_-1  theta_dot_offset_-1   \n",
       "0         1.086747        2.833017         0.142958            11.386702  \\\n",
       "1         1.623483        7.876772        -0.141752           -16.592314   \n",
       "2         2.660148       12.390169        -0.774046             3.583935   \n",
       "3         4.029298       15.247972        -0.718386            -2.368497   \n",
       "4         5.620429       16.578333        -0.761949             1.183639   \n",
       "...            ...             ...              ...                  ...   \n",
       "260231   18.675687        1.488769         0.202850            -3.183932   \n",
       "260232   18.761771        0.804798         0.117936             1.437662   \n",
       "260233   18.800924       -0.029675         0.400448             3.951609   \n",
       "260234   18.828193       -0.809622         0.645956             2.045812   \n",
       "260235   18.628204       -1.564804         0.785484             0.019339   \n",
       "\n",
       "        x_offset_-1  x_dot_offset_-1  z_offset_-1  z_dot_offset_-1  \n",
       "0        -17.930353         4.479441     1.045827        -1.884903  \n",
       "1        -17.582732         3.102667     1.086747         2.833017  \n",
       "2        -17.041003         7.492268     1.623483         7.876772  \n",
       "3        -16.071539        12.204198     2.660148        12.390169  \n",
       "4        -14.647161        16.036803     4.029298        15.247972  \n",
       "...             ...              ...          ...              ...  \n",
       "260231     1.355991         0.438261    18.497738         1.823627  \n",
       "260232     1.404614         0.325322    18.675687         1.488769  \n",
       "260233     1.405008         0.250367    18.761771         0.804798  \n",
       "260234     1.451527         0.169752    18.800924        -0.029675  \n",
       "260235     1.439573        -0.002924    18.828193        -0.809622  \n",
       "\n",
       "[260236 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augmented state data\n",
    "X = traj_augment_all.iloc[:, 0:n_state*delay_embedding]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a388bf-f12e-43e2-8a42-858b68e21272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j1_offset_0</th>\n",
       "      <th>j2_offset_0</th>\n",
       "      <th>j1_offset_-1</th>\n",
       "      <th>j2_offset_-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.049169</td>\n",
       "      <td>75.745171</td>\n",
       "      <td>-11.182978</td>\n",
       "      <td>59.740360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.380099</td>\n",
       "      <td>72.365653</td>\n",
       "      <td>8.049169</td>\n",
       "      <td>75.745171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.415249</td>\n",
       "      <td>54.432573</td>\n",
       "      <td>-2.380099</td>\n",
       "      <td>72.365653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.803299</td>\n",
       "      <td>31.557822</td>\n",
       "      <td>1.415249</td>\n",
       "      <td>54.432573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.490376</td>\n",
       "      <td>10.878398</td>\n",
       "      <td>-0.803299</td>\n",
       "      <td>31.557822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260231</th>\n",
       "      <td>1.002912</td>\n",
       "      <td>3.210493</td>\n",
       "      <td>1.887957</td>\n",
       "      <td>6.343482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260232</th>\n",
       "      <td>-0.742974</td>\n",
       "      <td>2.029763</td>\n",
       "      <td>1.002912</td>\n",
       "      <td>3.210493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260233</th>\n",
       "      <td>-0.819823</td>\n",
       "      <td>2.338930</td>\n",
       "      <td>-0.742974</td>\n",
       "      <td>2.029763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260234</th>\n",
       "      <td>0.028158</td>\n",
       "      <td>2.983043</td>\n",
       "      <td>-0.819823</td>\n",
       "      <td>2.338930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260235</th>\n",
       "      <td>-0.014556</td>\n",
       "      <td>3.875553</td>\n",
       "      <td>0.028158</td>\n",
       "      <td>2.983043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260236 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        j1_offset_0  j2_offset_0  j1_offset_-1  j2_offset_-1\n",
       "0          8.049169    75.745171    -11.182978     59.740360\n",
       "1         -2.380099    72.365653      8.049169     75.745171\n",
       "2          1.415249    54.432573     -2.380099     72.365653\n",
       "3         -0.803299    31.557822      1.415249     54.432573\n",
       "4          0.490376    10.878398     -0.803299     31.557822\n",
       "...             ...          ...           ...           ...\n",
       "260231     1.002912     3.210493      1.887957      6.343482\n",
       "260232    -0.742974     2.029763      1.002912      3.210493\n",
       "260233    -0.819823     2.338930     -0.742974      2.029763\n",
       "260234     0.028158     2.983043     -0.819823      2.338930\n",
       "260235    -0.014556     3.875553      0.028158      2.983043\n",
       "\n",
       "[260236 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augmented control data\n",
    "U = traj_augment_all.iloc[:, n_state*delay_embedding:n_state*delay_embedding+n_control*delay_embedding]\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26d35a6b-876e-46c4-872f-7b7f3adcff29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_optic_flow_offset_0</th>\n",
       "      <th>sensor_theta_offset_0</th>\n",
       "      <th>sensor_theta_dot_offset_0</th>\n",
       "      <th>sensor_accel_x_offset_0</th>\n",
       "      <th>sensor_accel_z_offset_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.855536</td>\n",
       "      <td>-0.129697</td>\n",
       "      <td>-16.569165</td>\n",
       "      <td>10.081994</td>\n",
       "      <td>65.260270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.561625</td>\n",
       "      <td>-0.796975</td>\n",
       "      <td>3.545528</td>\n",
       "      <td>51.148423</td>\n",
       "      <td>41.304389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.540573</td>\n",
       "      <td>-0.715709</td>\n",
       "      <td>-2.382807</td>\n",
       "      <td>36.139968</td>\n",
       "      <td>30.897068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.985252</td>\n",
       "      <td>-0.799967</td>\n",
       "      <td>1.188937</td>\n",
       "      <td>22.290788</td>\n",
       "      <td>12.499205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.240890</td>\n",
       "      <td>-0.763251</td>\n",
       "      <td>-0.819222</td>\n",
       "      <td>7.519336</td>\n",
       "      <td>-1.976989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260231</th>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.084429</td>\n",
       "      <td>1.433171</td>\n",
       "      <td>-0.344040</td>\n",
       "      <td>-6.620620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260232</th>\n",
       "      <td>-0.013789</td>\n",
       "      <td>0.369857</td>\n",
       "      <td>3.940717</td>\n",
       "      <td>-0.736389</td>\n",
       "      <td>-7.928407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260233</th>\n",
       "      <td>0.037798</td>\n",
       "      <td>0.706441</td>\n",
       "      <td>2.083396</td>\n",
       "      <td>-1.476087</td>\n",
       "      <td>-7.975956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260234</th>\n",
       "      <td>-0.025251</td>\n",
       "      <td>0.751732</td>\n",
       "      <td>-0.011484</td>\n",
       "      <td>-2.126294</td>\n",
       "      <td>-7.694932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260235</th>\n",
       "      <td>-0.019882</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>-2.781849</td>\n",
       "      <td>-7.047724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260236 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor_optic_flow_offset_0  sensor_theta_offset_0   \n",
       "0                         2.855536              -0.129697  \\\n",
       "1                         4.561625              -0.796975   \n",
       "2                         4.540573              -0.715709   \n",
       "3                         3.985252              -0.799967   \n",
       "4                         3.240890              -0.763251   \n",
       "...                            ...                    ...   \n",
       "260231                    0.000809               0.084429   \n",
       "260232                   -0.013789               0.369857   \n",
       "260233                    0.037798               0.706441   \n",
       "260234                   -0.025251               0.751732   \n",
       "260235                   -0.019882               0.757920   \n",
       "\n",
       "        sensor_theta_dot_offset_0  sensor_accel_x_offset_0   \n",
       "0                      -16.569165                10.081994  \\\n",
       "1                        3.545528                51.148423   \n",
       "2                       -2.382807                36.139968   \n",
       "3                        1.188937                22.290788   \n",
       "4                       -0.819222                 7.519336   \n",
       "...                           ...                      ...   \n",
       "260231                   1.433171                -0.344040   \n",
       "260232                   3.940717                -0.736389   \n",
       "260233                   2.083396                -1.476087   \n",
       "260234                  -0.011484                -2.126294   \n",
       "260235                   0.014505                -2.781849   \n",
       "\n",
       "        sensor_accel_z_offset_0  \n",
       "0                     65.260270  \n",
       "1                     41.304389  \n",
       "2                     30.897068  \n",
       "3                     12.499205  \n",
       "4                     -1.976989  \n",
       "...                         ...  \n",
       "260231                -6.620620  \n",
       "260232                -7.928407  \n",
       "260233                -7.975956  \n",
       "260234                -7.694932  \n",
       "260235                -7.047724  \n",
       "\n",
       "[260236 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output data\n",
    "Y = traj_augment_all.iloc[:, n_state*delay_embedding+n_control*delay_embedding:]\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2805ee-1afe-4585-9d76-f6bf648728d1",
   "metadata": {},
   "source": [
    "### combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85fa4ddd-5530-4fca-8692-efd469083623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the data so we have the core data, and augmented (delay embedded) data\n",
    "core_data = np.hstack((X.values[:, 0:n_state], U.values[:, 0:n_control]))\n",
    "#aux_data = np.hstack((X.values[:, n_state:], U.values[:, n_control:]))\n",
    "aux_data = core_data**-1\n",
    "output_data = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85819c02-a497-4360-aa8d-fddbd33f2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {'X_core_train': core_data,\n",
    "        'X_aux_train': aux_data,\n",
    "        'y_train': output_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f2e602-0de6-4def-8107-027d9c0d27e9",
   "metadata": {},
   "source": [
    "### Split up data into testing and training subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27d5e566-e8fe-4a33-9fa6-4289aa75032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split complete:\n",
      "  Training samples: 208188 (80%)\n",
      "  Test samples: 52048 (20%)\n",
      "  Core features: 8\n",
      "  Aux features: 8\n",
      "  Output dimension: 5\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "data = keras_advanced_utility.prepare_train_test_split(all_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b08cd6eb-0512-468a-bbda-da195bb0feca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_core_train', 'X_core_test', 'X_aux_train', 'X_aux_test', 'y_train', 'y_test'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a0daf0-5fac-440d-aedb-9c8c8fb30e03",
   "metadata": {},
   "source": [
    "# Build model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14c8217f-93d6-4277-84a6-c7729eff149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "core_architecture = [\n",
    "    {'units': 64, 'activation': 'tanh'},\n",
    "    {'units': 64, 'activation': 'tanh'}\n",
    "]\n",
    "\n",
    "aux_architecture = [\n",
    "    {'units': 64, 'activation': 'tanh'}\n",
    "]\n",
    "\n",
    "combined_architecture = [\n",
    "    {'units': 32, 'activation': 'linear'},\n",
    "    {'units': output_data.shape[1]}  # Output layer\n",
    "]\n",
    "\n",
    "input_architecture = {'core_input_dim': data['X_core_train'].shape[1],\n",
    "                      'aux_input_dim': data['X_aux_train'].shape[1]}\n",
    "\n",
    "\n",
    "training_parameters = {'jacobian_weight': 0.1,\n",
    "                       'sv_weight': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56ae4083-c408-4176-9237-7cd5c82abb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 12:46:34.233284: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "print(\"\\nBuilding model...\")\n",
    "model, dropout_layer = keras_advanced_utility.build_auxiliary_dropout_model(\n",
    "    core_input_dim=input_architecture['core_input_dim'],\n",
    "    aux_input_dim=input_architecture['aux_input_dim'],\n",
    "    core_architecture=core_architecture,\n",
    "    aux_architecture=aux_architecture,\n",
    "    combined_architecture=combined_architecture,\n",
    "    jacobian_weight=training_parameters['jacobian_weight'],\n",
    "    sv_weight=training_parameters['sv_weight']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bdb93ea-ef68-46c4-bc80-e30f52556b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"jacobian_regularized_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " core_features (InputLayer)  [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " aux_features (InputLayer)   [(None, 8)]                  0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   576       ['core_features[0][0]']       \n",
      "                                                                                                  \n",
      " aux_dropout (Dropout)       (None, 8)                    0         ['aux_features[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 64)                   4160      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   576       ['aux_dropout[0][0]']         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 128)                  0         ['dense_1[0][0]',             \n",
      "                                                                     'dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 32)                   4128      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 5)                    165       ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9609 (37.54 KB)\n",
      "Trainable params: 9605 (37.52 KB)\n",
      "Non-trainable params: 4 (16.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='mse', \n",
    "    metrics=['mae']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "386765a1-686d-4d0e-95ba-94bb811bbaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with curriculum learning...\n",
      "Curriculum learning schedule:\n",
      "  Total epochs: 200\n",
      "  Warmup epochs: 100 (50% of training)\n",
      "  Dropout: 0.50 → 0.99\n",
      "  Final dropout reached at epoch 100\n",
      "Epoch 1/200\n",
      "1302/1302 [==============================] - 10s 7ms/step - loss: 10.5465 - mae: 1.6011 - jacobian_smoothness: 1.3555e-05 - sv_loss: 0.0824 - val_loss: 6.7992 - val_mae: 1.1126 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5000 - val_mae_with_aux: 1.1122 - val_mae_without_aux: 1.0787\n",
      "Epoch 2/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 5.7892 - mae: 0.9685 - jacobian_smoothness: 8.2728e-05 - sv_loss: 2.8045e-04 - val_loss: 4.9971 - val_mae: 0.8663 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5049 - val_mae_with_aux: 0.8670 - val_mae_without_aux: 0.8382\n",
      "Epoch 3/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 4.6685 - mae: 0.7844 - jacobian_smoothness: 1.8801e-04 - sv_loss: 9.4659e-05 - val_loss: 4.1757 - val_mae: 0.7046 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5098 - val_mae_with_aux: 0.7037 - val_mae_without_aux: 0.6780\n",
      "Epoch 4/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 4.0238 - mae: 0.6312 - jacobian_smoothness: 4.1382e-04 - sv_loss: 2.9539e-05 - val_loss: 3.6466 - val_mae: 0.5592 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5147 - val_mae_with_aux: 0.5591 - val_mae_without_aux: 0.5351\n",
      "Epoch 5/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.6446 - mae: 0.5177 - jacobian_smoothness: 7.9804e-04 - sv_loss: 1.9529e-05 - val_loss: 3.3679 - val_mae: 0.4754 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5196 - val_mae_with_aux: 0.4752 - val_mae_without_aux: 0.4515\n",
      "Epoch 6/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.4539 - mae: 0.4583 - jacobian_smoothness: 0.0012 - sv_loss: 2.0206e-05 - val_loss: 3.2282 - val_mae: 0.4376 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5245 - val_mae_with_aux: 0.4377 - val_mae_without_aux: 0.4220\n",
      "Epoch 7/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.3573 - mae: 0.4257 - jacobian_smoothness: 0.0016 - sv_loss: 1.2633e-05 - val_loss: 3.1492 - val_mae: 0.4087 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5294 - val_mae_with_aux: 0.4091 - val_mae_without_aux: 0.3952\n",
      "Epoch 8/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.2944 - mae: 0.4036 - jacobian_smoothness: 0.0018 - sv_loss: 8.2482e-06 - val_loss: 3.0922 - val_mae: 0.3842 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5343 - val_mae_with_aux: 0.3846 - val_mae_without_aux: 0.3702\n",
      "Epoch 9/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.2502 - mae: 0.3886 - jacobian_smoothness: 0.0019 - sv_loss: 4.5534e-06 - val_loss: 3.0629 - val_mae: 0.3813 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5392 - val_mae_with_aux: 0.3812 - val_mae_without_aux: 0.3726\n",
      "Epoch 10/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.2170 - mae: 0.3755 - jacobian_smoothness: 0.0019 - sv_loss: 4.2452e-06 - val_loss: 3.0241 - val_mae: 0.3492 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5441 - val_mae_with_aux: 0.3492 - val_mae_without_aux: 0.3371\n",
      "Epoch 11/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.1928 - mae: 0.3645 - jacobian_smoothness: 0.0019 - sv_loss: 4.0055e-06 - val_loss: 2.9959 - val_mae: 0.3470 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5490 - val_mae_with_aux: 0.3473 - val_mae_without_aux: 0.3372\n",
      "Epoch 12/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.1708 - mae: 0.3561 - jacobian_smoothness: 0.0018 - sv_loss: 3.6059e-06 - val_loss: 2.9753 - val_mae: 0.3344 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5539 - val_mae_with_aux: 0.3343 - val_mae_without_aux: 0.3247\n",
      "Epoch 13/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.1532 - mae: 0.3490 - jacobian_smoothness: 0.0018 - sv_loss: 3.9286e-06 - val_loss: 2.9539 - val_mae: 0.3346 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5588 - val_mae_with_aux: 0.3343 - val_mae_without_aux: 0.3276\n",
      "Epoch 14/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.1375 - mae: 0.3427 - jacobian_smoothness: 0.0018 - sv_loss: 4.6540e-06 - val_loss: 2.9481 - val_mae: 0.3323 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5637 - val_mae_with_aux: 0.3324 - val_mae_without_aux: 0.3303\n",
      "Epoch 15/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.1249 - mae: 0.3371 - jacobian_smoothness: 0.0017 - sv_loss: 5.4218e-06 - val_loss: 2.9427 - val_mae: 0.3367 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5686 - val_mae_with_aux: 0.3366 - val_mae_without_aux: 0.3288\n",
      "Epoch 16/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.1128 - mae: 0.3322 - jacobian_smoothness: 0.0017 - sv_loss: 6.3576e-06 - val_loss: 2.9203 - val_mae: 0.3074 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5735 - val_mae_with_aux: 0.3076 - val_mae_without_aux: 0.3021\n",
      "Epoch 17/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.1018 - mae: 0.3272 - jacobian_smoothness: 0.0017 - sv_loss: 6.4984e-06 - val_loss: 2.9082 - val_mae: 0.3133 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5784 - val_mae_with_aux: 0.3134 - val_mae_without_aux: 0.3084\n",
      "Epoch 18/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0925 - mae: 0.3261 - jacobian_smoothness: 0.0017 - sv_loss: 7.7713e-06 - val_loss: 2.9092 - val_mae: 0.3203 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5833 - val_mae_with_aux: 0.3204 - val_mae_without_aux: 0.3196\n",
      "Epoch 19/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0862 - mae: 0.3226 - jacobian_smoothness: 0.0017 - sv_loss: 8.9350e-06 - val_loss: 2.9165 - val_mae: 0.3245 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5882 - val_mae_with_aux: 0.3243 - val_mae_without_aux: 0.3193\n",
      "Epoch 20/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0787 - mae: 0.3197 - jacobian_smoothness: 0.0017 - sv_loss: 9.3384e-06 - val_loss: 2.9000 - val_mae: 0.3149 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5931 - val_mae_with_aux: 0.3149 - val_mae_without_aux: 0.3106\n",
      "Epoch 21/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0747 - mae: 0.3172 - jacobian_smoothness: 0.0017 - sv_loss: 9.3731e-06 - val_loss: 2.8914 - val_mae: 0.3218 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.5980 - val_mae_with_aux: 0.3217 - val_mae_without_aux: 0.3200\n",
      "Epoch 22/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0677 - mae: 0.3154 - jacobian_smoothness: 0.0017 - sv_loss: 1.0244e-05 - val_loss: 2.8818 - val_mae: 0.3199 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6029 - val_mae_with_aux: 0.3198 - val_mae_without_aux: 0.3157\n",
      "Epoch 23/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0621 - mae: 0.3142 - jacobian_smoothness: 0.0017 - sv_loss: 1.0145e-05 - val_loss: 2.8796 - val_mae: 0.3013 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6078 - val_mae_with_aux: 0.3014 - val_mae_without_aux: 0.2972\n",
      "Epoch 24/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0592 - mae: 0.3112 - jacobian_smoothness: 0.0017 - sv_loss: 1.1270e-05 - val_loss: 2.8722 - val_mae: 0.3053 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6127 - val_mae_with_aux: 0.3055 - val_mae_without_aux: 0.3030\n",
      "Epoch 25/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0539 - mae: 0.3096 - jacobian_smoothness: 0.0017 - sv_loss: 1.0796e-05 - val_loss: 2.8623 - val_mae: 0.3073 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6176 - val_mae_with_aux: 0.3072 - val_mae_without_aux: 0.2994\n",
      "Epoch 26/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0502 - mae: 0.3084 - jacobian_smoothness: 0.0017 - sv_loss: 1.1370e-05 - val_loss: 2.8649 - val_mae: 0.3158 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6225 - val_mae_with_aux: 0.3159 - val_mae_without_aux: 0.3130\n",
      "Epoch 27/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0477 - mae: 0.3074 - jacobian_smoothness: 0.0017 - sv_loss: 1.0939e-05 - val_loss: 2.8601 - val_mae: 0.3060 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6274 - val_mae_with_aux: 0.3059 - val_mae_without_aux: 0.3005\n",
      "Epoch 28/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0441 - mae: 0.3054 - jacobian_smoothness: 0.0017 - sv_loss: 1.1006e-05 - val_loss: 2.8532 - val_mae: 0.2908 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6323 - val_mae_with_aux: 0.2908 - val_mae_without_aux: 0.2864\n",
      "Epoch 29/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0407 - mae: 0.3055 - jacobian_smoothness: 0.0017 - sv_loss: 1.2134e-05 - val_loss: 2.8474 - val_mae: 0.2903 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6372 - val_mae_with_aux: 0.2904 - val_mae_without_aux: 0.2893\n",
      "Epoch 30/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0393 - mae: 0.3047 - jacobian_smoothness: 0.0017 - sv_loss: 1.1206e-05 - val_loss: 2.8469 - val_mae: 0.2820 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6421 - val_mae_with_aux: 0.2821 - val_mae_without_aux: 0.2787\n",
      "Epoch 31/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0366 - mae: 0.3025 - jacobian_smoothness: 0.0017 - sv_loss: 1.1777e-05 - val_loss: 2.8708 - val_mae: 0.3183 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6470 - val_mae_with_aux: 0.3185 - val_mae_without_aux: 0.3161\n",
      "Epoch 32/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0349 - mae: 0.3029 - jacobian_smoothness: 0.0017 - sv_loss: 1.1627e-05 - val_loss: 2.8417 - val_mae: 0.2914 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6519 - val_mae_with_aux: 0.2914 - val_mae_without_aux: 0.2873\n",
      "Epoch 33/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0330 - mae: 0.3008 - jacobian_smoothness: 0.0017 - sv_loss: 1.0347e-05 - val_loss: 2.8391 - val_mae: 0.3059 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6568 - val_mae_with_aux: 0.3061 - val_mae_without_aux: 0.2969\n",
      "Epoch 34/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0289 - mae: 0.3013 - jacobian_smoothness: 0.0018 - sv_loss: 1.1860e-05 - val_loss: 2.8430 - val_mae: 0.2933 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6617 - val_mae_with_aux: 0.2932 - val_mae_without_aux: 0.2884\n",
      "Epoch 35/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0294 - mae: 0.3001 - jacobian_smoothness: 0.0018 - sv_loss: 1.0930e-05 - val_loss: 2.8361 - val_mae: 0.2820 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6666 - val_mae_with_aux: 0.2821 - val_mae_without_aux: 0.2788\n",
      "Epoch 36/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0265 - mae: 0.2988 - jacobian_smoothness: 0.0018 - sv_loss: 1.1249e-05 - val_loss: 2.8293 - val_mae: 0.2887 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6715 - val_mae_with_aux: 0.2886 - val_mae_without_aux: 0.2850\n",
      "Epoch 37/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0248 - mae: 0.2986 - jacobian_smoothness: 0.0018 - sv_loss: 1.1067e-05 - val_loss: 2.8303 - val_mae: 0.2876 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6764 - val_mae_with_aux: 0.2877 - val_mae_without_aux: 0.2860\n",
      "Epoch 38/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0233 - mae: 0.2989 - jacobian_smoothness: 0.0018 - sv_loss: 1.2330e-05 - val_loss: 2.8300 - val_mae: 0.2980 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6813 - val_mae_with_aux: 0.2981 - val_mae_without_aux: 0.2945\n",
      "Epoch 39/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0211 - mae: 0.2971 - jacobian_smoothness: 0.0018 - sv_loss: 1.0214e-05 - val_loss: 2.8339 - val_mae: 0.2901 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6862 - val_mae_with_aux: 0.2898 - val_mae_without_aux: 0.2871\n",
      "Epoch 40/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0201 - mae: 0.2975 - jacobian_smoothness: 0.0018 - sv_loss: 1.1209e-05 - val_loss: 2.8300 - val_mae: 0.2936 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6911 - val_mae_with_aux: 0.2936 - val_mae_without_aux: 0.2868\n",
      "Epoch 41/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0188 - mae: 0.2963 - jacobian_smoothness: 0.0018 - sv_loss: 1.1400e-05 - val_loss: 2.8226 - val_mae: 0.2816 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.6960 - val_mae_with_aux: 0.2817 - val_mae_without_aux: 0.2785\n",
      "Epoch 42/200\n",
      "1302/1302 [==============================] - 9s 7ms/step - loss: 3.0169 - mae: 0.2958 - jacobian_smoothness: 0.0018 - sv_loss: 1.0347e-05 - val_loss: 2.8273 - val_mae: 0.2870 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7009 - val_mae_with_aux: 0.2869 - val_mae_without_aux: 0.2787\n",
      "Epoch 43/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0169 - mae: 0.2951 - jacobian_smoothness: 0.0019 - sv_loss: 9.9396e-06 - val_loss: 2.8327 - val_mae: 0.2980 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7058 - val_mae_with_aux: 0.2980 - val_mae_without_aux: 0.2930\n",
      "Epoch 44/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0161 - mae: 0.2963 - jacobian_smoothness: 0.0019 - sv_loss: 9.6505e-06 - val_loss: 2.8162 - val_mae: 0.2860 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7107 - val_mae_with_aux: 0.2859 - val_mae_without_aux: 0.2797\n",
      "Epoch 45/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0142 - mae: 0.2948 - jacobian_smoothness: 0.0019 - sv_loss: 9.8074e-06 - val_loss: 2.8209 - val_mae: 0.2935 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7156 - val_mae_with_aux: 0.2936 - val_mae_without_aux: 0.2848\n",
      "Epoch 46/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0120 - mae: 0.2929 - jacobian_smoothness: 0.0019 - sv_loss: 9.5148e-06 - val_loss: 2.8259 - val_mae: 0.2908 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7205 - val_mae_with_aux: 0.2908 - val_mae_without_aux: 0.2866\n",
      "Epoch 47/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0116 - mae: 0.2931 - jacobian_smoothness: 0.0019 - sv_loss: 8.7566e-06 - val_loss: 2.8167 - val_mae: 0.2775 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7254 - val_mae_with_aux: 0.2772 - val_mae_without_aux: 0.2754\n",
      "Epoch 48/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0128 - mae: 0.2927 - jacobian_smoothness: 0.0019 - sv_loss: 8.6826e-06 - val_loss: 2.8540 - val_mae: 0.3093 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7303 - val_mae_with_aux: 0.3093 - val_mae_without_aux: 0.3080\n",
      "Epoch 49/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0094 - mae: 0.2923 - jacobian_smoothness: 0.0019 - sv_loss: 8.1505e-06 - val_loss: 2.8330 - val_mae: 0.3149 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7352 - val_mae_with_aux: 0.3149 - val_mae_without_aux: 0.3092\n",
      "Epoch 50/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0084 - mae: 0.2929 - jacobian_smoothness: 0.0019 - sv_loss: 8.4147e-06 - val_loss: 2.8159 - val_mae: 0.2981 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7401 - val_mae_with_aux: 0.2981 - val_mae_without_aux: 0.2964\n",
      "Epoch 51/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0083 - mae: 0.2919 - jacobian_smoothness: 0.0019 - sv_loss: 8.4891e-06 - val_loss: 2.8165 - val_mae: 0.2713 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7450 - val_mae_with_aux: 0.2712 - val_mae_without_aux: 0.2665\n",
      "Epoch 52/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0078 - mae: 0.2922 - jacobian_smoothness: 0.0020 - sv_loss: 7.5389e-06 - val_loss: 2.8101 - val_mae: 0.2753 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7499 - val_mae_with_aux: 0.2749 - val_mae_without_aux: 0.2734\n",
      "Epoch 53/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0054 - mae: 0.2916 - jacobian_smoothness: 0.0020 - sv_loss: 6.9354e-06 - val_loss: 2.8243 - val_mae: 0.2970 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7548 - val_mae_with_aux: 0.2972 - val_mae_without_aux: 0.2949\n",
      "Epoch 54/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0053 - mae: 0.2914 - jacobian_smoothness: 0.0020 - sv_loss: 8.3704e-06 - val_loss: 2.8140 - val_mae: 0.2851 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7597 - val_mae_with_aux: 0.2850 - val_mae_without_aux: 0.2809\n",
      "Epoch 55/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0050 - mae: 0.2906 - jacobian_smoothness: 0.0020 - sv_loss: 7.9074e-06 - val_loss: 2.8131 - val_mae: 0.2887 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7646 - val_mae_with_aux: 0.2887 - val_mae_without_aux: 0.2809\n",
      "Epoch 56/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0048 - mae: 0.2912 - jacobian_smoothness: 0.0021 - sv_loss: 7.1433e-06 - val_loss: 2.8074 - val_mae: 0.2848 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7695 - val_mae_with_aux: 0.2847 - val_mae_without_aux: 0.2800\n",
      "Epoch 57/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 3.0027 - mae: 0.2890 - jacobian_smoothness: 0.0020 - sv_loss: 7.3759e-06 - val_loss: 2.8086 - val_mae: 0.2852 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7744 - val_mae_with_aux: 0.2853 - val_mae_without_aux: 0.2827\n",
      "Epoch 58/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0018 - mae: 0.2899 - jacobian_smoothness: 0.0021 - sv_loss: 6.7799e-06 - val_loss: 2.8231 - val_mae: 0.3041 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7793 - val_mae_with_aux: 0.3039 - val_mae_without_aux: 0.2937\n",
      "Epoch 59/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0015 - mae: 0.2897 - jacobian_smoothness: 0.0021 - sv_loss: 6.9142e-06 - val_loss: 2.8216 - val_mae: 0.3016 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7842 - val_mae_with_aux: 0.3018 - val_mae_without_aux: 0.2959\n",
      "Epoch 60/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9997 - mae: 0.2887 - jacobian_smoothness: 0.0021 - sv_loss: 9.6934e-06 - val_loss: 2.8071 - val_mae: 0.2737 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7891 - val_mae_with_aux: 0.2735 - val_mae_without_aux: 0.2713\n",
      "Epoch 61/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0013 - mae: 0.2887 - jacobian_smoothness: 0.0021 - sv_loss: 7.2417e-06 - val_loss: 2.8036 - val_mae: 0.2733 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7940 - val_mae_with_aux: 0.2734 - val_mae_without_aux: 0.2702\n",
      "Epoch 62/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 3.0010 - mae: 0.2878 - jacobian_smoothness: 0.0021 - sv_loss: 8.4599e-06 - val_loss: 2.8044 - val_mae: 0.2823 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.7989 - val_mae_with_aux: 0.2822 - val_mae_without_aux: 0.2791\n",
      "Epoch 63/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9992 - mae: 0.2877 - jacobian_smoothness: 0.0021 - sv_loss: 9.1161e-06 - val_loss: 2.8040 - val_mae: 0.2801 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8038 - val_mae_with_aux: 0.2802 - val_mae_without_aux: 0.2798\n",
      "Epoch 64/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9966 - mae: 0.2872 - jacobian_smoothness: 0.0022 - sv_loss: 7.7286e-06 - val_loss: 2.7992 - val_mae: 0.2859 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8087 - val_mae_with_aux: 0.2860 - val_mae_without_aux: 0.2816\n",
      "Epoch 65/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9981 - mae: 0.2873 - jacobian_smoothness: 0.0022 - sv_loss: 8.5135e-06 - val_loss: 2.8060 - val_mae: 0.2840 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8136 - val_mae_with_aux: 0.2840 - val_mae_without_aux: 0.2811\n",
      "Epoch 66/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9978 - mae: 0.2870 - jacobian_smoothness: 0.0022 - sv_loss: 9.2405e-06 - val_loss: 2.8108 - val_mae: 0.2711 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8185 - val_mae_with_aux: 0.2711 - val_mae_without_aux: 0.2687\n",
      "Epoch 67/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9953 - mae: 0.2871 - jacobian_smoothness: 0.0022 - sv_loss: 9.3705e-06 - val_loss: 2.8020 - val_mae: 0.2691 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8234 - val_mae_with_aux: 0.2690 - val_mae_without_aux: 0.2651\n",
      "Epoch 68/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9975 - mae: 0.2864 - jacobian_smoothness: 0.0022 - sv_loss: 9.5603e-06 - val_loss: 2.8275 - val_mae: 0.3158 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8283 - val_mae_with_aux: 0.3158 - val_mae_without_aux: 0.3111\n",
      "Epoch 69/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9946 - mae: 0.2871 - jacobian_smoothness: 0.0023 - sv_loss: 9.9291e-06 - val_loss: 2.8008 - val_mae: 0.2683 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8332 - val_mae_with_aux: 0.2683 - val_mae_without_aux: 0.2636\n",
      "Epoch 70/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9931 - mae: 0.2855 - jacobian_smoothness: 0.0023 - sv_loss: 9.3528e-06 - val_loss: 2.8045 - val_mae: 0.2881 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8381 - val_mae_with_aux: 0.2882 - val_mae_without_aux: 0.2816\n",
      "Epoch 71/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9958 - mae: 0.2869 - jacobian_smoothness: 0.0023 - sv_loss: 1.0270e-05 - val_loss: 2.7964 - val_mae: 0.2806 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8430 - val_mae_with_aux: 0.2807 - val_mae_without_aux: 0.2754\n",
      "Epoch 72/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9953 - mae: 0.2863 - jacobian_smoothness: 0.0023 - sv_loss: 1.3550e-05 - val_loss: 2.8048 - val_mae: 0.2789 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8479 - val_mae_with_aux: 0.2789 - val_mae_without_aux: 0.2743\n",
      "Epoch 73/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9916 - mae: 0.2860 - jacobian_smoothness: 0.0023 - sv_loss: 1.5969e-05 - val_loss: 2.8096 - val_mae: 0.2964 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8528 - val_mae_with_aux: 0.2964 - val_mae_without_aux: 0.2965\n",
      "Epoch 74/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9917 - mae: 0.2855 - jacobian_smoothness: 0.0024 - sv_loss: 1.2190e-05 - val_loss: 2.7978 - val_mae: 0.2645 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8577 - val_mae_with_aux: 0.2644 - val_mae_without_aux: 0.2606\n",
      "Epoch 75/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9922 - mae: 0.2846 - jacobian_smoothness: 0.0024 - sv_loss: 1.3939e-05 - val_loss: 2.8389 - val_mae: 0.3051 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8626 - val_mae_with_aux: 0.3051 - val_mae_without_aux: 0.3015\n",
      "Epoch 76/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9920 - mae: 0.2848 - jacobian_smoothness: 0.0024 - sv_loss: 1.7139e-05 - val_loss: 2.7968 - val_mae: 0.2797 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8675 - val_mae_with_aux: 0.2798 - val_mae_without_aux: 0.2776\n",
      "Epoch 77/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9911 - mae: 0.2845 - jacobian_smoothness: 0.0024 - sv_loss: 1.6972e-05 - val_loss: 2.7998 - val_mae: 0.2859 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8724 - val_mae_with_aux: 0.2859 - val_mae_without_aux: 0.2847\n",
      "Epoch 78/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9896 - mae: 0.2840 - jacobian_smoothness: 0.0024 - sv_loss: 1.6908e-05 - val_loss: 2.7930 - val_mae: 0.2801 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8773 - val_mae_with_aux: 0.2801 - val_mae_without_aux: 0.2766\n",
      "Epoch 79/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9889 - mae: 0.2853 - jacobian_smoothness: 0.0025 - sv_loss: 1.7105e-05 - val_loss: 2.7995 - val_mae: 0.2751 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8822 - val_mae_with_aux: 0.2751 - val_mae_without_aux: 0.2729\n",
      "Epoch 80/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9901 - mae: 0.2831 - jacobian_smoothness: 0.0025 - sv_loss: 1.7531e-05 - val_loss: 2.7981 - val_mae: 0.2819 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8871 - val_mae_with_aux: 0.2817 - val_mae_without_aux: 0.2785\n",
      "Epoch 81/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9912 - mae: 0.2848 - jacobian_smoothness: 0.0025 - sv_loss: 2.0895e-05 - val_loss: 2.7974 - val_mae: 0.2770 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8920 - val_mae_with_aux: 0.2770 - val_mae_without_aux: 0.2731\n",
      "Epoch 82/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9878 - mae: 0.2839 - jacobian_smoothness: 0.0026 - sv_loss: 2.0030e-05 - val_loss: 2.8182 - val_mae: 0.3017 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.8969 - val_mae_with_aux: 0.3018 - val_mae_without_aux: 0.2943\n",
      "Epoch 83/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9884 - mae: 0.2835 - jacobian_smoothness: 0.0026 - sv_loss: 2.3257e-05 - val_loss: 2.8078 - val_mae: 0.2940 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9018 - val_mae_with_aux: 0.2940 - val_mae_without_aux: 0.2922\n",
      "Epoch 84/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9881 - mae: 0.2832 - jacobian_smoothness: 0.0026 - sv_loss: 2.2926e-05 - val_loss: 2.7898 - val_mae: 0.2786 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9067 - val_mae_with_aux: 0.2786 - val_mae_without_aux: 0.2749\n",
      "Epoch 85/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9851 - mae: 0.2834 - jacobian_smoothness: 0.0026 - sv_loss: 2.2933e-05 - val_loss: 2.7947 - val_mae: 0.2855 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9116 - val_mae_with_aux: 0.2856 - val_mae_without_aux: 0.2808\n",
      "Epoch 86/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9858 - mae: 0.2837 - jacobian_smoothness: 0.0027 - sv_loss: 2.2137e-05 - val_loss: 2.8036 - val_mae: 0.2700 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9165 - val_mae_with_aux: 0.2700 - val_mae_without_aux: 0.2654\n",
      "Epoch 87/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9881 - mae: 0.2829 - jacobian_smoothness: 0.0027 - sv_loss: 2.2874e-05 - val_loss: 2.7987 - val_mae: 0.2792 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9214 - val_mae_with_aux: 0.2793 - val_mae_without_aux: 0.2756\n",
      "Epoch 88/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9863 - mae: 0.2821 - jacobian_smoothness: 0.0027 - sv_loss: 2.7967e-05 - val_loss: 2.7941 - val_mae: 0.2854 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9263 - val_mae_with_aux: 0.2855 - val_mae_without_aux: 0.2836\n",
      "Epoch 89/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9856 - mae: 0.2824 - jacobian_smoothness: 0.0027 - sv_loss: 2.7238e-05 - val_loss: 2.8127 - val_mae: 0.2980 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9312 - val_mae_with_aux: 0.2980 - val_mae_without_aux: 0.2898\n",
      "Epoch 90/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9851 - mae: 0.2832 - jacobian_smoothness: 0.0028 - sv_loss: 2.9166e-05 - val_loss: 2.7936 - val_mae: 0.2680 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9361 - val_mae_with_aux: 0.2678 - val_mae_without_aux: 0.2639\n",
      "Epoch 91/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9871 - mae: 0.2827 - jacobian_smoothness: 0.0029 - sv_loss: 2.6889e-05 - val_loss: 2.7927 - val_mae: 0.2776 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9410 - val_mae_with_aux: 0.2775 - val_mae_without_aux: 0.2728\n",
      "Epoch 92/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9829 - mae: 0.2826 - jacobian_smoothness: 0.0029 - sv_loss: 2.9002e-05 - val_loss: 2.8011 - val_mae: 0.2734 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9459 - val_mae_with_aux: 0.2733 - val_mae_without_aux: 0.2715\n",
      "Epoch 93/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9846 - mae: 0.2820 - jacobian_smoothness: 0.0029 - sv_loss: 2.9928e-05 - val_loss: 2.8001 - val_mae: 0.2824 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9508 - val_mae_with_aux: 0.2823 - val_mae_without_aux: 0.2808\n",
      "Epoch 94/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9823 - mae: 0.2818 - jacobian_smoothness: 0.0029 - sv_loss: 3.5661e-05 - val_loss: 2.8003 - val_mae: 0.2909 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9557 - val_mae_with_aux: 0.2909 - val_mae_without_aux: 0.2849\n",
      "Epoch 95/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9844 - mae: 0.2810 - jacobian_smoothness: 0.0029 - sv_loss: 2.8449e-05 - val_loss: 2.7861 - val_mae: 0.2777 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9606 - val_mae_with_aux: 0.2777 - val_mae_without_aux: 0.2728\n",
      "Epoch 96/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9828 - mae: 0.2825 - jacobian_smoothness: 0.0030 - sv_loss: 2.7862e-05 - val_loss: 2.8125 - val_mae: 0.2880 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9655 - val_mae_with_aux: 0.2879 - val_mae_without_aux: 0.2893\n",
      "Epoch 97/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9835 - mae: 0.2816 - jacobian_smoothness: 0.0030 - sv_loss: 3.0479e-05 - val_loss: 2.7884 - val_mae: 0.2796 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9704 - val_mae_with_aux: 0.2797 - val_mae_without_aux: 0.2727\n",
      "Epoch 98/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9830 - mae: 0.2823 - jacobian_smoothness: 0.0032 - sv_loss: 3.0007e-05 - val_loss: 2.7858 - val_mae: 0.2683 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9753 - val_mae_with_aux: 0.2685 - val_mae_without_aux: 0.2623\n",
      "Epoch 99/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9826 - mae: 0.2802 - jacobian_smoothness: 0.0030 - sv_loss: 3.0111e-05 - val_loss: 2.8348 - val_mae: 0.3053 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9802 - val_mae_with_aux: 0.3054 - val_mae_without_aux: 0.3062\n",
      "Epoch 100/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9812 - mae: 0.2814 - jacobian_smoothness: 0.0031 - sv_loss: 3.2643e-05 - val_loss: 2.7983 - val_mae: 0.2855 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9851 - val_mae_with_aux: 0.2853 - val_mae_without_aux: 0.2772\n",
      "Epoch 101/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9786 - mae: 0.2807 - jacobian_smoothness: 0.0032 - sv_loss: 3.1756e-05 - val_loss: 2.7880 - val_mae: 0.2788 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2787 - val_mae_without_aux: 0.2728\n",
      "Epoch 102/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9804 - mae: 0.2803 - jacobian_smoothness: 0.0032 - sv_loss: 3.1046e-05 - val_loss: 2.8041 - val_mae: 0.2892 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2890 - val_mae_without_aux: 0.2869\n",
      "Epoch 103/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9811 - mae: 0.2820 - jacobian_smoothness: 0.0034 - sv_loss: 3.5004e-05 - val_loss: 2.7941 - val_mae: 0.2766 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2766 - val_mae_without_aux: 0.2714\n",
      "Epoch 104/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9786 - mae: 0.2817 - jacobian_smoothness: 0.0035 - sv_loss: 3.7039e-05 - val_loss: 2.7930 - val_mae: 0.2708 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2706 - val_mae_without_aux: 0.2664\n",
      "Epoch 105/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9795 - mae: 0.2811 - jacobian_smoothness: 0.0033 - sv_loss: 3.2274e-05 - val_loss: 2.7952 - val_mae: 0.2694 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2694 - val_mae_without_aux: 0.2643\n",
      "Epoch 106/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9820 - mae: 0.2815 - jacobian_smoothness: 0.0033 - sv_loss: 3.0669e-05 - val_loss: 2.7993 - val_mae: 0.2821 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2819 - val_mae_without_aux: 0.2743\n",
      "Epoch 107/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9795 - mae: 0.2802 - jacobian_smoothness: 0.0033 - sv_loss: 3.6920e-05 - val_loss: 2.7963 - val_mae: 0.2886 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2887 - val_mae_without_aux: 0.2854\n",
      "Epoch 108/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9817 - mae: 0.2802 - jacobian_smoothness: 0.0035 - sv_loss: 3.7922e-05 - val_loss: 2.7872 - val_mae: 0.2715 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2712 - val_mae_without_aux: 0.2643\n",
      "Epoch 109/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9768 - mae: 0.2798 - jacobian_smoothness: 0.0035 - sv_loss: 3.3737e-05 - val_loss: 2.7851 - val_mae: 0.2749 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2753 - val_mae_without_aux: 0.2731\n",
      "Epoch 110/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9788 - mae: 0.2801 - jacobian_smoothness: 0.0036 - sv_loss: 3.9658e-05 - val_loss: 2.7995 - val_mae: 0.2707 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2709 - val_mae_without_aux: 0.2666\n",
      "Epoch 111/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9777 - mae: 0.2808 - jacobian_smoothness: 0.0037 - sv_loss: 3.4898e-05 - val_loss: 2.7873 - val_mae: 0.2696 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2696 - val_mae_without_aux: 0.2664\n",
      "Epoch 112/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9764 - mae: 0.2796 - jacobian_smoothness: 0.0036 - sv_loss: 3.4382e-05 - val_loss: 2.7805 - val_mae: 0.2660 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2661 - val_mae_without_aux: 0.2631\n",
      "Epoch 113/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9770 - mae: 0.2792 - jacobian_smoothness: 0.0037 - sv_loss: 3.6368e-05 - val_loss: 2.7834 - val_mae: 0.2660 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2662 - val_mae_without_aux: 0.2632\n",
      "Epoch 114/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9750 - mae: 0.2800 - jacobian_smoothness: 0.0039 - sv_loss: 3.8264e-05 - val_loss: 2.7911 - val_mae: 0.2873 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2873 - val_mae_without_aux: 0.2836\n",
      "Epoch 115/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9745 - mae: 0.2791 - jacobian_smoothness: 0.0037 - sv_loss: 3.7221e-05 - val_loss: 2.7853 - val_mae: 0.2584 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2583 - val_mae_without_aux: 0.2552\n",
      "Epoch 116/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9764 - mae: 0.2796 - jacobian_smoothness: 0.0037 - sv_loss: 4.0625e-05 - val_loss: 2.7870 - val_mae: 0.2631 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2633 - val_mae_without_aux: 0.2576\n",
      "Epoch 117/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9767 - mae: 0.2793 - jacobian_smoothness: 0.0038 - sv_loss: 4.1005e-05 - val_loss: 2.7953 - val_mae: 0.2815 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2816 - val_mae_without_aux: 0.2774\n",
      "Epoch 118/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9766 - mae: 0.2790 - jacobian_smoothness: 0.0038 - sv_loss: 3.8346e-05 - val_loss: 2.7869 - val_mae: 0.2820 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2821 - val_mae_without_aux: 0.2821\n",
      "Epoch 119/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9764 - mae: 0.2802 - jacobian_smoothness: 0.0039 - sv_loss: 4.3881e-05 - val_loss: 2.7911 - val_mae: 0.2828 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2828 - val_mae_without_aux: 0.2790\n",
      "Epoch 120/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9746 - mae: 0.2807 - jacobian_smoothness: 0.0042 - sv_loss: 4.2180e-05 - val_loss: 2.7810 - val_mae: 0.2618 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2619 - val_mae_without_aux: 0.2580\n",
      "Epoch 121/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9757 - mae: 0.2795 - jacobian_smoothness: 0.0042 - sv_loss: 4.3726e-05 - val_loss: 2.7834 - val_mae: 0.2791 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2789 - val_mae_without_aux: 0.2749\n",
      "Epoch 122/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9722 - mae: 0.2790 - jacobian_smoothness: 0.0041 - sv_loss: 4.6905e-05 - val_loss: 2.7843 - val_mae: 0.2641 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2638 - val_mae_without_aux: 0.2629\n",
      "Epoch 123/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9737 - mae: 0.2791 - jacobian_smoothness: 0.0043 - sv_loss: 4.4305e-05 - val_loss: 2.7847 - val_mae: 0.2731 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2730 - val_mae_without_aux: 0.2722\n",
      "Epoch 124/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9752 - mae: 0.2784 - jacobian_smoothness: 0.0043 - sv_loss: 4.1878e-05 - val_loss: 2.7993 - val_mae: 0.2834 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2835 - val_mae_without_aux: 0.2813\n",
      "Epoch 125/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9768 - mae: 0.2790 - jacobian_smoothness: 0.0045 - sv_loss: 4.6022e-05 - val_loss: 2.7918 - val_mae: 0.2818 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2816 - val_mae_without_aux: 0.2746\n",
      "Epoch 126/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9737 - mae: 0.2786 - jacobian_smoothness: 0.0044 - sv_loss: 4.6156e-05 - val_loss: 2.8049 - val_mae: 0.2924 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2925 - val_mae_without_aux: 0.2920\n",
      "Epoch 127/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9751 - mae: 0.2801 - jacobian_smoothness: 0.0042 - sv_loss: 4.3883e-05 - val_loss: 2.7859 - val_mae: 0.2694 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2695 - val_mae_without_aux: 0.2648\n",
      "Epoch 128/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9745 - mae: 0.2778 - jacobian_smoothness: 0.0046 - sv_loss: 4.7978e-05 - val_loss: 2.7836 - val_mae: 0.2633 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2629 - val_mae_without_aux: 0.2586\n",
      "Epoch 129/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9735 - mae: 0.2782 - jacobian_smoothness: 0.0045 - sv_loss: 5.1139e-05 - val_loss: 2.7881 - val_mae: 0.2681 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2680 - val_mae_without_aux: 0.2608\n",
      "Epoch 130/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9726 - mae: 0.2776 - jacobian_smoothness: 0.0047 - sv_loss: 4.4739e-05 - val_loss: 2.7887 - val_mae: 0.2857 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2856 - val_mae_without_aux: 0.2822\n",
      "Epoch 131/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9737 - mae: 0.2778 - jacobian_smoothness: 0.0048 - sv_loss: 5.0950e-05 - val_loss: 2.7920 - val_mae: 0.2736 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2736 - val_mae_without_aux: 0.2713\n",
      "Epoch 132/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9727 - mae: 0.2796 - jacobian_smoothness: 0.0045 - sv_loss: 5.3717e-05 - val_loss: 2.8014 - val_mae: 0.2897 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2898 - val_mae_without_aux: 0.2836\n",
      "Epoch 133/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9726 - mae: 0.2781 - jacobian_smoothness: 0.0050 - sv_loss: 5.1666e-05 - val_loss: 2.7860 - val_mae: 0.2622 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2623 - val_mae_without_aux: 0.2602\n",
      "Epoch 134/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9709 - mae: 0.2773 - jacobian_smoothness: 0.0050 - sv_loss: 4.9591e-05 - val_loss: 2.7852 - val_mae: 0.2668 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2667 - val_mae_without_aux: 0.2643\n",
      "Epoch 135/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9727 - mae: 0.2779 - jacobian_smoothness: 0.0048 - sv_loss: 4.7947e-05 - val_loss: 2.7826 - val_mae: 0.2777 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2779 - val_mae_without_aux: 0.2767\n",
      "Epoch 136/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9710 - mae: 0.2773 - jacobian_smoothness: 0.0051 - sv_loss: 5.3603e-05 - val_loss: 2.7984 - val_mae: 0.2956 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2961 - val_mae_without_aux: 0.2933\n",
      "Epoch 137/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9715 - mae: 0.2781 - jacobian_smoothness: 0.0049 - sv_loss: 5.5623e-05 - val_loss: 2.7911 - val_mae: 0.2940 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2942 - val_mae_without_aux: 0.2932\n",
      "Epoch 138/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9722 - mae: 0.2780 - jacobian_smoothness: 0.0051 - sv_loss: 5.0833e-05 - val_loss: 2.7849 - val_mae: 0.2718 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2715 - val_mae_without_aux: 0.2691\n",
      "Epoch 139/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9712 - mae: 0.2769 - jacobian_smoothness: 0.0052 - sv_loss: 5.6213e-05 - val_loss: 2.7820 - val_mae: 0.2833 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2834 - val_mae_without_aux: 0.2811\n",
      "Epoch 140/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9709 - mae: 0.2778 - jacobian_smoothness: 0.0053 - sv_loss: 5.2379e-05 - val_loss: 2.7836 - val_mae: 0.2810 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2808 - val_mae_without_aux: 0.2749\n",
      "Epoch 141/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9713 - mae: 0.2776 - jacobian_smoothness: 0.0052 - sv_loss: 5.0350e-05 - val_loss: 2.7789 - val_mae: 0.2691 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2691 - val_mae_without_aux: 0.2692\n",
      "Epoch 142/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9718 - mae: 0.2787 - jacobian_smoothness: 0.0049 - sv_loss: 5.7492e-05 - val_loss: 2.7913 - val_mae: 0.2688 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2688 - val_mae_without_aux: 0.2680\n",
      "Epoch 143/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9718 - mae: 0.2768 - jacobian_smoothness: 0.0051 - sv_loss: 5.9587e-05 - val_loss: 2.7821 - val_mae: 0.2718 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2719 - val_mae_without_aux: 0.2675\n",
      "Epoch 144/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9709 - mae: 0.2769 - jacobian_smoothness: 0.0049 - sv_loss: 5.5907e-05 - val_loss: 2.7902 - val_mae: 0.2749 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2749 - val_mae_without_aux: 0.2705\n",
      "Epoch 145/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9708 - mae: 0.2770 - jacobian_smoothness: 0.0051 - sv_loss: 5.2496e-05 - val_loss: 2.7791 - val_mae: 0.2755 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2754 - val_mae_without_aux: 0.2737\n",
      "Epoch 146/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9682 - mae: 0.2770 - jacobian_smoothness: 0.0057 - sv_loss: 5.7534e-05 - val_loss: 2.7783 - val_mae: 0.2808 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2808 - val_mae_without_aux: 0.2798\n",
      "Epoch 147/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9697 - mae: 0.2770 - jacobian_smoothness: 0.0056 - sv_loss: 5.5861e-05 - val_loss: 2.7826 - val_mae: 0.2660 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2661 - val_mae_without_aux: 0.2612\n",
      "Epoch 148/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9698 - mae: 0.2764 - jacobian_smoothness: 0.0052 - sv_loss: 5.7209e-05 - val_loss: 2.7906 - val_mae: 0.2826 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2824 - val_mae_without_aux: 0.2789\n",
      "Epoch 149/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9679 - mae: 0.2787 - jacobian_smoothness: 0.0059 - sv_loss: 5.5591e-05 - val_loss: 2.7801 - val_mae: 0.2627 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2626 - val_mae_without_aux: 0.2603\n",
      "Epoch 150/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9688 - mae: 0.2771 - jacobian_smoothness: 0.0056 - sv_loss: 5.6980e-05 - val_loss: 2.7945 - val_mae: 0.2681 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2681 - val_mae_without_aux: 0.2664\n",
      "Epoch 151/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9687 - mae: 0.2786 - jacobian_smoothness: 0.0055 - sv_loss: 6.0217e-05 - val_loss: 2.7817 - val_mae: 0.2596 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2594 - val_mae_without_aux: 0.2583\n",
      "Epoch 152/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9674 - mae: 0.2776 - jacobian_smoothness: 0.0053 - sv_loss: 5.4554e-05 - val_loss: 2.7831 - val_mae: 0.2665 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2664 - val_mae_without_aux: 0.2637\n",
      "Epoch 153/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9686 - mae: 0.2781 - jacobian_smoothness: 0.0061 - sv_loss: 6.2768e-05 - val_loss: 2.7814 - val_mae: 0.2764 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2762 - val_mae_without_aux: 0.2721\n",
      "Epoch 154/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9675 - mae: 0.2773 - jacobian_smoothness: 0.0053 - sv_loss: 6.6746e-05 - val_loss: 2.7908 - val_mae: 0.2826 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2825 - val_mae_without_aux: 0.2783\n",
      "Epoch 155/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9685 - mae: 0.2780 - jacobian_smoothness: 0.0060 - sv_loss: 5.9186e-05 - val_loss: 2.7829 - val_mae: 0.2664 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2663 - val_mae_without_aux: 0.2670\n",
      "Epoch 156/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9687 - mae: 0.2764 - jacobian_smoothness: 0.0057 - sv_loss: 6.4645e-05 - val_loss: 2.7829 - val_mae: 0.2629 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2630 - val_mae_without_aux: 0.2573\n",
      "Epoch 157/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9683 - mae: 0.2762 - jacobian_smoothness: 0.0055 - sv_loss: 5.7734e-05 - val_loss: 2.7767 - val_mae: 0.2628 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2626 - val_mae_without_aux: 0.2605\n",
      "Epoch 158/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9664 - mae: 0.2757 - jacobian_smoothness: 0.0063 - sv_loss: 6.3217e-05 - val_loss: 2.7900 - val_mae: 0.2749 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2752 - val_mae_without_aux: 0.2734\n",
      "Epoch 159/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9668 - mae: 0.2775 - jacobian_smoothness: 0.0056 - sv_loss: 5.8205e-05 - val_loss: 2.7876 - val_mae: 0.2695 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2696 - val_mae_without_aux: 0.2664\n",
      "Epoch 160/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9665 - mae: 0.2773 - jacobian_smoothness: 0.0060 - sv_loss: 5.8152e-05 - val_loss: 2.7794 - val_mae: 0.2734 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2731 - val_mae_without_aux: 0.2706\n",
      "Epoch 161/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9656 - mae: 0.2767 - jacobian_smoothness: 0.0062 - sv_loss: 6.4787e-05 - val_loss: 2.7784 - val_mae: 0.2689 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2690 - val_mae_without_aux: 0.2663\n",
      "Epoch 162/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9669 - mae: 0.2762 - jacobian_smoothness: 0.0063 - sv_loss: 6.0845e-05 - val_loss: 2.7849 - val_mae: 0.2694 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2693 - val_mae_without_aux: 0.2657\n",
      "Epoch 163/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9655 - mae: 0.2781 - jacobian_smoothness: 0.0062 - sv_loss: 6.4831e-05 - val_loss: 2.7800 - val_mae: 0.2540 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2542 - val_mae_without_aux: 0.2525\n",
      "Epoch 164/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9660 - mae: 0.2773 - jacobian_smoothness: 0.0061 - sv_loss: 6.1755e-05 - val_loss: 2.7769 - val_mae: 0.2658 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2658 - val_mae_without_aux: 0.2636\n",
      "Epoch 165/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9658 - mae: 0.2765 - jacobian_smoothness: 0.0062 - sv_loss: 6.2382e-05 - val_loss: 2.7804 - val_mae: 0.2707 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2706 - val_mae_without_aux: 0.2670\n",
      "Epoch 166/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9617 - mae: 0.2769 - jacobian_smoothness: 0.0061 - sv_loss: 6.6776e-05 - val_loss: 2.7754 - val_mae: 0.2583 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2583 - val_mae_without_aux: 0.2551\n",
      "Epoch 167/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9652 - mae: 0.2770 - jacobian_smoothness: 0.0067 - sv_loss: 7.2099e-05 - val_loss: 2.7809 - val_mae: 0.2623 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2623 - val_mae_without_aux: 0.2600\n",
      "Epoch 168/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9664 - mae: 0.2774 - jacobian_smoothness: 0.0068 - sv_loss: 6.4564e-05 - val_loss: 2.7758 - val_mae: 0.2581 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2580 - val_mae_without_aux: 0.2539\n",
      "Epoch 169/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9652 - mae: 0.2763 - jacobian_smoothness: 0.0062 - sv_loss: 6.7116e-05 - val_loss: 2.7808 - val_mae: 0.2733 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2735 - val_mae_without_aux: 0.2678\n",
      "Epoch 170/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9657 - mae: 0.2778 - jacobian_smoothness: 0.0060 - sv_loss: 6.3107e-05 - val_loss: 2.7856 - val_mae: 0.2753 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2752 - val_mae_without_aux: 0.2688\n",
      "Epoch 171/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9650 - mae: 0.2761 - jacobian_smoothness: 0.0063 - sv_loss: 6.2175e-05 - val_loss: 2.7906 - val_mae: 0.2906 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2907 - val_mae_without_aux: 0.2887\n",
      "Epoch 172/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9638 - mae: 0.2776 - jacobian_smoothness: 0.0073 - sv_loss: 6.7176e-05 - val_loss: 2.8003 - val_mae: 0.2638 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2637 - val_mae_without_aux: 0.2590\n",
      "Epoch 173/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9632 - mae: 0.2762 - jacobian_smoothness: 0.0064 - sv_loss: 6.6676e-05 - val_loss: 2.7852 - val_mae: 0.2696 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2693 - val_mae_without_aux: 0.2658\n",
      "Epoch 174/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9655 - mae: 0.2775 - jacobian_smoothness: 0.0067 - sv_loss: 6.7294e-05 - val_loss: 2.7782 - val_mae: 0.2702 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2701 - val_mae_without_aux: 0.2663\n",
      "Epoch 175/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9635 - mae: 0.2764 - jacobian_smoothness: 0.0074 - sv_loss: 7.1639e-05 - val_loss: 2.7844 - val_mae: 0.2696 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2696 - val_mae_without_aux: 0.2664\n",
      "Epoch 176/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9618 - mae: 0.2759 - jacobian_smoothness: 0.0067 - sv_loss: 5.7585e-05 - val_loss: 2.7850 - val_mae: 0.2879 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2879 - val_mae_without_aux: 0.2848\n",
      "Epoch 177/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9644 - mae: 0.2769 - jacobian_smoothness: 0.0069 - sv_loss: 6.9573e-05 - val_loss: 2.7776 - val_mae: 0.2531 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2532 - val_mae_without_aux: 0.2522\n",
      "Epoch 178/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9632 - mae: 0.2761 - jacobian_smoothness: 0.0068 - sv_loss: 6.5872e-05 - val_loss: 2.7831 - val_mae: 0.2856 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2857 - val_mae_without_aux: 0.2824\n",
      "Epoch 179/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9608 - mae: 0.2760 - jacobian_smoothness: 0.0070 - sv_loss: 6.6680e-05 - val_loss: 2.7775 - val_mae: 0.2732 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2731 - val_mae_without_aux: 0.2726\n",
      "Epoch 180/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9642 - mae: 0.2766 - jacobian_smoothness: 0.0065 - sv_loss: 5.7050e-05 - val_loss: 2.7866 - val_mae: 0.2778 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2778 - val_mae_without_aux: 0.2721\n",
      "Epoch 181/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9640 - mae: 0.2765 - jacobian_smoothness: 0.0074 - sv_loss: 6.0334e-05 - val_loss: 2.7922 - val_mae: 0.2710 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2708 - val_mae_without_aux: 0.2660\n",
      "Epoch 182/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9654 - mae: 0.2766 - jacobian_smoothness: 0.0072 - sv_loss: 6.2231e-05 - val_loss: 2.7790 - val_mae: 0.2684 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2683 - val_mae_without_aux: 0.2626\n",
      "Epoch 183/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9638 - mae: 0.2754 - jacobian_smoothness: 0.0068 - sv_loss: 6.7871e-05 - val_loss: 2.7983 - val_mae: 0.2847 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2847 - val_mae_without_aux: 0.2839\n",
      "Epoch 184/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9624 - mae: 0.2757 - jacobian_smoothness: 0.0076 - sv_loss: 6.6355e-05 - val_loss: 2.7750 - val_mae: 0.2678 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2677 - val_mae_without_aux: 0.2640\n",
      "Epoch 185/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9603 - mae: 0.2759 - jacobian_smoothness: 0.0072 - sv_loss: 7.3367e-05 - val_loss: 2.7902 - val_mae: 0.2723 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2725 - val_mae_without_aux: 0.2671\n",
      "Epoch 186/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9625 - mae: 0.2766 - jacobian_smoothness: 0.0073 - sv_loss: 5.9879e-05 - val_loss: 2.7779 - val_mae: 0.2615 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2616 - val_mae_without_aux: 0.2615\n",
      "Epoch 187/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9628 - mae: 0.2766 - jacobian_smoothness: 0.0067 - sv_loss: 7.1155e-05 - val_loss: 2.7840 - val_mae: 0.2862 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2863 - val_mae_without_aux: 0.2833\n",
      "Epoch 188/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9642 - mae: 0.2762 - jacobian_smoothness: 0.0066 - sv_loss: 6.4163e-05 - val_loss: 2.7761 - val_mae: 0.2585 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2586 - val_mae_without_aux: 0.2554\n",
      "Epoch 189/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9615 - mae: 0.2758 - jacobian_smoothness: 0.0083 - sv_loss: 6.3193e-05 - val_loss: 2.7752 - val_mae: 0.2582 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2582 - val_mae_without_aux: 0.2556\n",
      "Epoch 190/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9612 - mae: 0.2755 - jacobian_smoothness: 0.0082 - sv_loss: 6.1324e-05 - val_loss: 2.7754 - val_mae: 0.2727 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2726 - val_mae_without_aux: 0.2679\n",
      "Epoch 191/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9609 - mae: 0.2767 - jacobian_smoothness: 0.0073 - sv_loss: 7.5352e-05 - val_loss: 2.7721 - val_mae: 0.2609 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2610 - val_mae_without_aux: 0.2563\n",
      "Epoch 192/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9647 - mae: 0.2759 - jacobian_smoothness: 0.0072 - sv_loss: 6.1650e-05 - val_loss: 2.7814 - val_mae: 0.2730 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2729 - val_mae_without_aux: 0.2725\n",
      "Epoch 193/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9627 - mae: 0.2757 - jacobian_smoothness: 0.0072 - sv_loss: 6.5814e-05 - val_loss: 2.7792 - val_mae: 0.2796 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2795 - val_mae_without_aux: 0.2777\n",
      "Epoch 194/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9583 - mae: 0.2762 - jacobian_smoothness: 0.0077 - sv_loss: 6.7216e-05 - val_loss: 2.7771 - val_mae: 0.2549 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2550 - val_mae_without_aux: 0.2483\n",
      "Epoch 195/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9626 - mae: 0.2764 - jacobian_smoothness: 0.0077 - sv_loss: 6.5091e-05 - val_loss: 2.7908 - val_mae: 0.2838 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2839 - val_mae_without_aux: 0.2776\n",
      "Epoch 196/200\n",
      "1302/1302 [==============================] - 7s 6ms/step - loss: 2.9594 - mae: 0.2751 - jacobian_smoothness: 0.0082 - sv_loss: 6.0054e-05 - val_loss: 2.7870 - val_mae: 0.2606 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2605 - val_mae_without_aux: 0.2576\n",
      "Epoch 197/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9601 - mae: 0.2759 - jacobian_smoothness: 0.0074 - sv_loss: 6.9085e-05 - val_loss: 2.7753 - val_mae: 0.2743 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2743 - val_mae_without_aux: 0.2689\n",
      "Epoch 198/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9613 - mae: 0.2764 - jacobian_smoothness: 0.0084 - sv_loss: 6.8384e-05 - val_loss: 2.7831 - val_mae: 0.2604 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2605 - val_mae_without_aux: 0.2558\n",
      "Epoch 199/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9584 - mae: 0.2762 - jacobian_smoothness: 0.0082 - sv_loss: 6.6238e-05 - val_loss: 2.7773 - val_mae: 0.2706 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2705 - val_mae_without_aux: 0.2665\n",
      "Epoch 200/200\n",
      "1302/1302 [==============================] - 8s 6ms/step - loss: 2.9596 - mae: 0.2757 - jacobian_smoothness: 0.0081 - sv_loss: 6.5715e-05 - val_loss: 2.7839 - val_mae: 0.2776 - val_jacobian_smoothness: 0.0000e+00 - val_sv_loss: 0.0000e+00 - dropout_rate: 0.9900 - val_mae_with_aux: 0.2775 - val_mae_without_aux: 0.2672\n"
     ]
    }
   ],
   "source": [
    "# Train with curriculum learning\n",
    "print(\"\\nTraining with curriculum learning...\")\n",
    "history, curriculum_callback, X_core_val, X_aux_val, y_val = keras_advanced_utility.train_with_curriculum(\n",
    "    model=model,\n",
    "    dropout_layer=dropout_layer,\n",
    "    X_core_train=data['X_core_train'],\n",
    "    X_aux_train=data['X_aux_train'],\n",
    "    y_train=data['y_train'],\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=128,\n",
    "    initial_dropout=0.5, # start with dropping out 20% of the auxilliary inputs\n",
    "    final_dropout=0.99,  # end with dropping out 95% of the auxiliary inputs\n",
    "    warmup_fraction=0.5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebdb3fb3-b087-452a-8144-6fa7618415bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALIDATION SET PERFORMANCE:\n",
      "============================================================\n",
      "MAE without auxiliary features: 0.2672\n",
      "MAE with auxiliary features:    0.2775\n",
      "⚠ Without aux performs 3.72% better\n",
      "\n",
      "============================================================\n",
      "TEST SET PERFORMANCE:\n",
      "============================================================\n",
      "MAE without auxiliary features: 0.2722\n",
      "MAE with auxiliary features:    0.2824\n",
      "⚠ Without aux performs 3.62% better\n",
      "\n",
      "Generating visualizations...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'khf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Visualize results\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenerating visualizations...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mkhf\u001b[49m\u001b[38;5;241m.\u001b[39mvisualize_results(\n\u001b[1;32m      9\u001b[0m     history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m     10\u001b[0m     curriculum_callback\u001b[38;5;241m=\u001b[39mcurriculum_callback,\n\u001b[1;32m     11\u001b[0m     val_results\u001b[38;5;241m=\u001b[39mval_results,\n\u001b[1;32m     12\u001b[0m     test_results\u001b[38;5;241m=\u001b[39mtest_results,\n\u001b[1;32m     13\u001b[0m     y_val\u001b[38;5;241m=\u001b[39my_val,\n\u001b[1;32m     14\u001b[0m     y_test\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m     X_core_test\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_core_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     17\u001b[0m     X_aux_test\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_aux_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSUMMARY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'khf' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation and test sets\n",
    "val_results = keras_advanced_utility.evaluate_model(model, X_core_val, X_aux_val, y_val, \"Validation\")\n",
    "test_results = keras_advanced_utility.evaluate_model(model, data['X_core_test'], data['X_aux_test'], \n",
    "                               data['y_test'], \"Test\")\n",
    "\n",
    "# Visualize results\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "khf.visualize_results(\n",
    "    history=history,\n",
    "    curriculum_callback=curriculum_callback,\n",
    "    val_results=val_results,\n",
    "    test_results=test_results,\n",
    "    y_val=y_val,\n",
    "    y_test=data['y_test'],\n",
    "    model=model,\n",
    "    X_core_test=data['X_core_test'],\n",
    "    X_aux_test=data['X_aux_test']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final dropout rate: {curriculum_callback.dropout_history[-1]:.2f}\")\n",
    "print(f\"Mean Jacobian norm: {np.linalg.norm(np.random.randn(10, 5), axis=1).mean():.4f}\")\n",
    "print(\"\\nTraining complete! Check 'curriculum_dropout_results.png' for visualizations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d640767-6beb-4e7e-887e-8802bd8198a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_advanced_utility.save_model_complete(\n",
    "    model=model,\n",
    "    filepath='smooth_measurements_model',  # No extension needed\n",
    "    core_architecture=core_architecture,\n",
    "    aux_architecture=aux_architecture,\n",
    "    combined_architecture=combined_architecture,\n",
    "    input_architecture=input_architecture,\n",
    "    training_parameters=training_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefda46c-16b2-4ebe-848d-a1822bfbc446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
